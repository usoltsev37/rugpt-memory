{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07d70b90-86b6-46ae-a61c-d75a6822ff88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:27:21.982414Z",
     "start_time": "2024-03-21T11:27:19.411012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "import transformers\n",
    "from tqdm.auto import tqdm, trange\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9ef6a2-72c4-4642-9b64-29c41d30506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "SRC_SUBDIR = '../src/'\n",
    "SRC_SUBDIR = osp.abspath(SRC_SUBDIR)\n",
    "if SRC_SUBDIR not in sys.path:\n",
    "    print(f'Adding source directory to the sys.path: {SRC_SUBDIR!r}')\n",
    "    sys.path.insert(1, SRC_SUBDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ea78975-2b61-457c-b0d6-2985b887ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  features\t__init__.py  models  __pycache__  utils  visualization\n"
     ]
    }
   ],
   "source": [
    "!ls ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa6c23c6-e5fc-41e5-a693-9c9e479d260d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../src',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../src',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/study/repositories/rugpt-memory/src',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages',\n",
       " '/tmp/tmpq3ceq4ua']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f71944af-6f5b-4488-bf54-18b72f0a872e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../src',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../src',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python310.zip/../',\n",
       " '/home/usoltsev/study/repositories/rugpt-memory/src',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages',\n",
       " '/tmp/tmpq3ceq4ua']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../'))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae86e75a-04a0-477f-b995-961b0e49fa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/usoltsev/study/repositories/rugpt-memory/notebooks'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c415686-d7ce-451c-a20c-3634da7239c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/usoltsev/study/repositories/rugpt-memory/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a84bad69-2a68-4bf5-97c6-e8c6d4e4670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.ltm_gpt.ltm_gpt import LTM_GPT\n",
    "from src.utils.train_config import load_config\n",
    "from src.models.load_base_model import load_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32228070-433f-435f-8143-ca51b2b5be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -L 1 .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd4d12bf-62e4-466f-93f8-8b6fe7db15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13f7cfbe-2698-4e4b-83c2-3d56dd4424cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-03-23 17:50:17,532: INFO] Loading base model (load_base_model.py:9)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:   0%|                                                   | 0/6 [00:00<?, ?it/s]/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████| 6/6 [00:07<00:00,  1.29s/it]\n",
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "main_config = load_config('/home/usoltsev/study/repositories/rugpt-memory/configs/finetuning_codeparrot.yml')\n",
    "\n",
    "model, tokenizer = load_base_model(main_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b71809a-5d10-4471-bae6-ff738da2e438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 23 17:50:43 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.146.02             Driver Version: 535.146.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:19:00.0 Off |                  N/A |\n",
      "| 30%   33C    P5             104W / 350W |  12865MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        Off | 00000000:65:00.0 Off |                  N/A |\n",
      "| 30%   32C    P5              95W / 350W |  12353MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1597      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A   1138911      C   ...iniforge3/envs/rugpt_dev/bin/python    12850MiB |\n",
      "|    1   N/A  N/A      1597      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A   1138911      C   ...iniforge3/envs/rugpt_dev/bin/python    12338MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d54e9dc2-f0e1-4a1f-b6f2-6df62625a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_blocks_with_memory = 2\n",
    "\n",
    "model = LTM_GPT(\n",
    "    model,\n",
    "    cnt_blocks_with_memory=cnt_blocks_with_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea33771e-46dc-439d-a1de-4696dd5eb180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 23 17:53:39 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.146.02             Driver Version: 535.146.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:19:00.0 Off |                  N/A |\n",
      "| 30%   31C    P2             125W / 350W |  16485MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        Off | 00000000:65:00.0 Off |                  N/A |\n",
      "| 30%   30C    P2             107W / 350W |  12353MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1597      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A   1138911      C   ...iniforge3/envs/rugpt_dev/bin/python    16470MiB |\n",
      "|    1   N/A  N/A      1597      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A   1138911      C   ...iniforge3/envs/rugpt_dev/bin/python    12338MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c49f32a-ed46-4c05-857f-8e867ec7f5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/usoltsev/study/repositories/rugpt-memory/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2deb6bda-617c-4d5a-a488-280effaabf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bde617f-8595-4bb7-8225-5fe4a3bd08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = accelerator.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64bf5eca-32d2-464f-a801-8e85151ef583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 23 18:13:20 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.146.02             Driver Version: 535.146.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:19:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8              27W / 350W |  16485MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        Off | 00000000:65:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8              30W / 350W |  12353MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1597      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A   1138911      C   ...iniforge3/envs/rugpt_dev/bin/python    16470MiB |\n",
      "|    1   N/A  N/A      1597      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A   1138911      C   ...iniforge3/envs/rugpt_dev/bin/python    12338MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a732a37-d9f8-4962-847f-722feb140643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a1d127e-a0e1-4a2c-9eb9-dabcf168688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[33076]], device='cuda:0'), 'attention_mask': tensor([[1]], device='cuda:0')}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m after_finetuning_samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m---> 40\u001b[0m     after_finetuning_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcustom_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_STEPS\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(after_finetuning_samples)\n",
      "Cell \u001b[0;32mIn[47], line 23\u001b[0m, in \u001b[0;36mcustom_generate\u001b[0;34m(prompt, model, device, max_steps)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n\u001b[0;32m---> 23\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# print(outputs)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     probs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnan_to_num(nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m0.8\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# .argmax(-1).reshape(1, 1)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/study/repositories/rugpt-memory/src/models/ltm_gpt/ltm_gpt.py:77\u001b[0m, in \u001b[0;36mLTM_GPT.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m---> 77\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Init memory as hidden_states from 37 layers\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# BaseModelOutputWithPastAndCrossAttentions(\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#     last_hidden_state=hidden_states,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#     cross_attentions=all_cross_attentions,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:888\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    876\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    877\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    878\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m         output_attentions,\n\u001b[1;32m    886\u001b[0m     )\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:389\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    379\u001b[0m     hidden_states: Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    387\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor], Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]]:\n\u001b[1;32m    388\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 389\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m     attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m    391\u001b[0m         hidden_states,\n\u001b[1;32m    392\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    397\u001b[0m     )\n\u001b[1;32m    398\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/normalization.py:196\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/functional.py:2543\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2541\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2542\u001b[0m     )\n\u001b[0;32m-> 2543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)"
     ]
    }
   ],
   "source": [
    "for param in model.transformer.h[-cnt_blocks_with_memory:].parameters():\n",
    "    param.requires_grad=True\n",
    "    # param.data = param.data.to(torch.float32)\n",
    "\n",
    "for param in model.transformer.ln_f.parameters():\n",
    "    param.requires_grad=True\n",
    "    # param.data = param.data.to(torch.float32)\n",
    "\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad=True\n",
    "    # param.data = param.data.to(torch.float32)\n",
    "\n",
    "prompts = ['import', 'from', 'while', 'try', 'if', 'for',\n",
    "           'torch']  # feel free to add a few more that are not 100% assiciated with Python\n",
    "\n",
    "MAX_STEPS = 100\n",
    "\n",
    "def custom_generate(prompt, model, device, max_steps):\n",
    "    batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
    "    print(batch)\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        outputs = model(**batch)\n",
    "        # print(outputs)\n",
    "        probs = outputs.logits[0, -1].nan_to_num(nan=0.0).div(0.8).softmax(-1)  # .argmax(-1).reshape(1, 1)\n",
    "        old_token = outputs.logits[0, -1].argmax(-1).reshape(1, 1)\n",
    "        # print(old_token)\n",
    "        next_token = torch.multinomial(probs, 1).reshape(1, 1)\n",
    "        # print(next_token)\n",
    "        batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
    "        batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
    "        break\n",
    "\n",
    "    return tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()[1:])\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "after_finetuning_samples = []\n",
    "for prompt in prompts:\n",
    "    after_finetuning_samples.append(custom_generate(prompt, model, device, MAX_STEPS))\n",
    "print(after_finetuning_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0471d514-48f2-4aa7-b23a-0c33acbea02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2024-03-23 18:26:34,977: INFO] Loading dataset (load_codeparrot_dataset.py:7)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_codeparrot_dataset import load_codeparrot_dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "dataset = load_codeparrot_dataset(tokenizer)\n",
    "\n",
    "# logger.info('Initializing tensorboard')\n",
    "tensorboard_logs_dir = f'logs/tensorboard/{main_config.exp_name}/'\n",
    "tensorboard_writer = SummaryWriter(tensorboard_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84fb97ca-5dfa-4d44-9f7d-dc34f0e2bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.info('Training')\n",
    "model._hf_peft_config_loaded = True # silence warnings - for research it is ok\n",
    "model.config.use_cache = False # silence warnings from torch\n",
    "\n",
    "trainer_args = main_config.trainer_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2515d74e-9a73-48f3-ad0f-a804d455a86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab6a98c-bdfc-4c0e-bc75-04f7711224b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa18d118-3353-4b4b-a2db-83ead97478ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.94 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.30 GiB is allocated by PyTorch, and 13.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorBoardCallback\n\u001b[0;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m accelerator\u001b[38;5;241m.\u001b[39mprepare(\u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogging_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/outputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_checkpointing_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_reentrant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataCollatorForLanguageModeling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mTensorBoardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtb_writer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_writer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/transformers/trainer.py:489\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    488\u001b[0m ):\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/transformers/trainer.py:730\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 730\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/transformers/modeling_utils.py:2556\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2555\u001b[0m         )\n\u001b[0;32m-> 2556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.94 MiB is free. Including non-PyTorch memory, this process has 23.62 GiB memory in use. Of the allocated memory 23.30 GiB is allocated by PyTorch, and 13.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers.integrations import TensorBoardCallback\n",
    "trainer = accelerator.prepare(transformers.Trainer(\n",
    "    model=model, train_dataset=dataset['train'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=trainer_args.per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=trainer_args.gradient_accumulation_steps,\n",
    "        warmup_steps=trainer_args.warmup_steps,\n",
    "        max_steps=trainer_args.max_steps,\n",
    "        learning_rate=trainer_args.learning_rate,\n",
    "        fp16=trainer_args.fp16,\n",
    "        logging_steps=trainer_args.logging_steps,\n",
    "        output_dir=f'checkpoints/{main_config.exp_name}/outputs',\n",
    "        report_to=trainer_args.report_to,\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    callbacks=[TensorBoardCallback(tb_writer=tensorboard_writer)]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd98813-009d-4a5a-ae34-aa89a15501a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f6b6f-a2f0-4b24-b711-c6a6f7bad126",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a1e58-6ef7-4f10-b731-0bba6a8c827e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d89a7-deb4-411f-928c-4bc1ead21c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b21fd3-262f-40e8-bf08-7a1e093306e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|                                                   | 0/6 [00:00<?, ?it/s]/home/usoltsev/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████| 6/6 [00:15<00:00,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"ai-forever/ruGPT-3.5-13B\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    "    low_cpu_mem_usage=True,\n",
    "    offload_state_dict=True, \n",
    "    cache_dir=\"/home/usoltsev/study/repositories/rugpt-memory/checkpoints/base/huggingface/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca9e42f0-c970-43dd-884c-23416616e4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50272, 5120)\n",
       "    (wpe): Embedding(2048, 5120)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-39): 40 x GPT2Block(\n",
       "        (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f426fc-5d30-4fa9-a948-df28c5242568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7112129a-154f-4ff1-8dfd-11ff9ad8f5bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2Block' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPT2Block' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "model.transformer.h[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d721d-12c2-47bc-a338-75f068cd384b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf5795-c261-4671-b0b8-cf375d5279bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71636e-70df-48a9-907e-81713ae799a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38ca59e-0f38-4936-b167-dca71157e6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50272, 5120)\n",
       "    (wpe): Embedding(2048, 5120)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-39): 40 x GPT2Block(\n",
       "        (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): CastOutputToFloat(\n",
       "    (0): Linear(in_features=5120, out_features=50272, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimization \n",
    "model.gradient_checkpointing_enable() # memory optimization: only store a small subset of activations, re-compute the rest.\n",
    "model.enable_input_require_grads() # override an implementation quirk in gradient checkpoints that disables backprop unless inputs require grad\n",
    "class CastOutputToFloat(torch.nn.Sequential):\n",
    "    def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head) # cast model ouputs to unfuct the top-k sampler\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adcfd939-88e9-4a5d-ae55-69adf7d730ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetwork(nn.Module):\n",
    "    \"\"\" DenseNetwork layer(FeedForward in original paper) \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        embed_dim=5120,\n",
    "        hidden_size=10240, \n",
    "        dtype=torch.float32,\n",
    "        initialize_with_zeros=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.ln1 = nn.Linear(self.embed_dim, self.hidden_size, dtype=self.dtype)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln2 = nn.Linear(self.hidden_size, self.embed_dim, dtype=self.dtype)\n",
    "        \n",
    "        if initialize_with_zeros:\n",
    "            nn.init.zeros_(self.ln1.weight)\n",
    "            nn.init.zeros_(self.ln1.bias)\n",
    "            nn.init.zeros_(self.ln2.weight)\n",
    "            nn.init.zeros_(self.ln2.bias)\n",
    "    \n",
    "    def forward(self, x): # x: (sentence_length, batch_size, self.embed_dim)\n",
    "        x = self.ln1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.ln2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21c3b9d-d868-4da9-9576-bb0b14271371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTMGPT2Block(nn.Module):\n",
    "    \"\"\" Custom LTMGPT2Block layer with memory \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        gpt2_block,\n",
    "        num_heads=4,\n",
    "        attn_dropout=0.1,\n",
    "        dense_network_hidden_size=10240,\n",
    "        dtype=torch.float32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.gpt2_block = gpt2_block\n",
    "        \n",
    "        self.embed_dim = self.gpt2_block.ln_1.normalized_shape[0]\n",
    "        self.dense_network_hidden_size = dense_network_hidden_size\n",
    "        \n",
    "        assert dtype in [torch.float16, torch.float32]\n",
    "        \n",
    "        # self.memory: ( , , ) / (target_sentence_length, batch_size, self.embed_dim) (5120) | torch.FloatTensor / nn.Embedding\n",
    "        self.memory = None\n",
    "        \n",
    "        # goal: convert memory from ( , , ) to (source_sentence_length, batch_size, self.embed_dim)\n",
    "        self.dense_network1 = DenseNetwork(\n",
    "            embed_dim=self.embed_dim,\n",
    "            hidden_size=self.dense_network_hidden_size, \n",
    "            dtype=dtype,\n",
    "            initialize_with_zeros=False\n",
    "        )\n",
    "        \n",
    "        self.attn = nn.MultiheadAttention( # TODO masked ????\n",
    "            embed_dim=self.embed_dim, \n",
    "            num_heads=num_heads, \n",
    "            dropout=attn_dropout,\n",
    "            batch_first=False,\n",
    "            dtype=dtype\n",
    "        )\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(self.embed_dim)\n",
    "        \n",
    "        self.dense_network2 = DenseNetwork(\n",
    "            embed_dim=self.embed_dim,\n",
    "            hidden_size=self.dense_network_hidden_size, \n",
    "            dtype=dtype,\n",
    "            initialize_with_zeros=True\n",
    "        )\n",
    "        \n",
    "        self.ln2 = nn.LayerNorm(self.embed_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x): # x: (sentence_length, batch_size, self.embed_dim)\n",
    "        assert not self.memory\n",
    "        \n",
    "        # TransformerBlock\n",
    "        query = self.gpt2_block(x) # query: (sentence_length, batch_size, self.embed_dim)\n",
    "        residual = query\n",
    "        \n",
    "        # DenseNetowork\n",
    "        memory = self.dense_network1(self.memory)\n",
    "        \n",
    "        # MultiHead Attention\n",
    "        key, value = memory, memory\n",
    "        x, _ = self.attn(\n",
    "            query=query, \n",
    "            key=key, \n",
    "            value=value\n",
    "        )\n",
    "        \n",
    "        # Norm & Concat\n",
    "        x = x + residual\n",
    "        if self.dtype == torch.float16:\n",
    "            x = self.ln1(x.float()).type(torch.float16)\n",
    "        else:\n",
    "            x = self.ln1(x)\n",
    "        \n",
    "        # DenseNetowork initialized with zeroes\n",
    "        x = self.dense_network2(x)\n",
    "        \n",
    "        # Norm & Concat\n",
    "        x = x + residual\n",
    "        if self.dtype == torch.float16:\n",
    "            x = self.ln2(x.float()).type(torch.float16)\n",
    "        else:\n",
    "            x = self.ln2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def update_memory(new_memory):\n",
    "        self.memory = new_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8653cf5f-9dda-4cc8-aa0a-6716ed36bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c18b069-0212-4846-a4e0-5dc30f6d3e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50272, 5120)\n",
       "    (wpe): Embedding(2048, 5120)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-39): 40 x GPT2Block(\n",
       "        (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): CastOutputToFloat(\n",
       "    (0): Linear(in_features=5120, out_features=50272, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ce9e95-25ac-4719-b43e-4f2876e46c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50272, 5120)\n",
       "  (wpe): Embedding(2048, 5120)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-39): 40 x GPT2Block(\n",
       "      (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer#.output_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed359c8c-60ce-4f95-8319-ec9ecbaf03bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.config.output_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ce9b6c1-c4a3-4ef7-ac83-6074754fe42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53ee1899-c0db-48ad-9d16-25cee60dd02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.config.output_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3f2d0e-e043-49f0-8928-265b24b0a16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2b4899-b087-48e8-b5b4-c5ff5639614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50272, 5120)\n",
       "    (wpe): Embedding(2048, 5120)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-39): 40 x GPT2Block(\n",
       "        (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): CastOutputToFloat(\n",
       "    (0): Linear(in_features=5120, out_features=50272, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65df8fa-112e-4ce7-8fc3-902d4ffae236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.modeling_gpt2 import GPT2LMHeadModel\n",
    "from transformers.utils import (\n",
    "    ModelOutput,\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutputWithPast,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "from typing import Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e453079-a7c2-4b42-84d2-8a5f3baa9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTM_GPT(GPT2LMHeadModel):\n",
    "    \"\"\" Custom LTM GPT2 layer with memory \"\"\"\n",
    "    def __init__(self, model_: GPT2LMHeadModel, cnt_blocks_with_memory=2):\n",
    "        super().__init__(model.config)\n",
    "        print(type(model_))\n",
    "        self.base_model = model_\n",
    "        print(type(self.base_model))\n",
    "        self.transformer = model.transformer\n",
    "        self.transformer.h = model_.transformer.h[:-cnt_blocks_with_memory]\n",
    "        \n",
    "        self.transformer_ltm_blocks = nn.ModuleList([\n",
    "            LTMGPT2Block(model_.transformer.h[-cnt_blocks_with_memory+i]) for i in range(cnt_blocks_with_memory)\n",
    "        ])\n",
    "        \n",
    "        self.lm_head = model_.lm_head\n",
    "\n",
    "        # Model parallel\n",
    "        # self.model_parallel = False\n",
    "        # self.device_map = None\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        # self.post_init()\n",
    "    \n",
    "    # @add_start_docstrings_to_model_forward(GPT2_INPUTS_DOCSTRING)\n",
    "    # @add_code_sample_docstrings(\n",
    "    #     checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "    #     output_type=CausalLMOutputWithCrossAttentions,\n",
    "    #     config_class=_CONFIG_FOR_DOC,\n",
    "    # )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithCrossAttentions]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\n",
    "            `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\n",
    "            are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.base_model.config.use_return_dict\n",
    "\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        \n",
    "        # Init memory as hidden_states from 37 layers\n",
    "        # BaseModelOutputWithPastAndCrossAttentions(\n",
    "        #     last_hidden_state=hidden_states,\n",
    "        #     past_key_values=presents,\n",
    "        #     hidden_states=all_hidden_states,\n",
    "        #     attentions=all_self_attentions,\n",
    "        #     cross_attentions=all_cross_attentions,\n",
    "        # )    \n",
    "        \n",
    "        print(len(transformer_outputs))\n",
    "        memory = transformer_outputs[2][37]\n",
    "        \n",
    "        for block in self.transformer_ltm_blocks:\n",
    "            block.update_memory(memory)\n",
    "            hidden_states = block(hidden_states)\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.base_model.model_parallel:\n",
    "            torch.cuda.set_device(self.transformer.first_device)\n",
    "            hidden_states = hidden_states.to(self.lm_head.weight.device)\n",
    "\n",
    "        lm_logits = self.lm_head(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # move labels to correct device to enable model parallelism\n",
    "            labels = labels.to(lm_logits.device)\n",
    "            # Shift so that tokens < n predict n\n",
    "            shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            # Flatten the tokens\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + transformer_outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithCrossAttentions(\n",
    "            loss=loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=transformer_outputs.past_key_values,\n",
    "            hidden_states=transformer_outputs.hidden_states,\n",
    "            attentions=transformer_outputs.attentions,\n",
    "            cross_attentions=transformer_outputs.cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db84c847-4af6-4bb2-85dd-84bf88fe58db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/usoltsev/study/repositories/rugpt-memory/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca888cf-b28a-42ec-a34b-17973ed45244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50272, 5120)\n",
       "  (wpe): Embedding(2048, 5120)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-39): 40 x GPT2Block(\n",
       "      (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b11797-eb55-40d9-ab70-8cf0fac86caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d0f4cc8-11dd-4f02-abfe-f1f4850a512f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2Model"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3530d76-79da-48f2-b3e0-979d0dc28688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n"
     ]
    }
   ],
   "source": [
    "model = LTM_GPT(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0e18dd6-6c01-45b3-bcfd-6ebc8dfdcf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LTM_GPT(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50272, 5120)\n",
       "    (wpe): Embedding(2048, 5120)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-37): 38 x GPT2Block(\n",
       "        (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): CastOutputToFloat(\n",
       "    (0): Linear(in_features=5120, out_features=50272, bias=False)\n",
       "  )\n",
       "  (base_model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50272, 5120)\n",
       "      (wpe): Embedding(2048, 5120)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-37): 38 x GPT2Block(\n",
       "          (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): CastOutputToFloat(\n",
       "      (0): Linear(in_features=5120, out_features=50272, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (transformer_ltm_blocks): ModuleList(\n",
       "    (0-1): 2 x LTMGPT2Block(\n",
       "      (gpt2_block): GPT2Block(\n",
       "        (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (dense_network1): DenseNetwork(\n",
       "        (ln1): Linear(in_features=5120, out_features=10240, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (ln2): Linear(in_features=10240, out_features=5120, bias=True)\n",
       "      )\n",
       "      (attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=5120, out_features=5120, bias=True)\n",
       "      )\n",
       "      (ln1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "      (dense_network2): DenseNetwork(\n",
       "        (ln1): Linear(in_features=5120, out_features=10240, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (ln2): Linear(in_features=10240, out_features=5120, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cac44d17-c996-4a8b-99ef-f74ce23451b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruGPT-3.5-13B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e589cab-0e0d-49cc-94e1-150bd924db15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "code_dataset = load_dataset(\"codeparrot/codeparrot-clean-valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f611d769-a31d-46bf-a574-cd6711eac9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 420.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[33076]]), 'attention_mask': tensor([[1]])}\n",
      "{'input_ids': tensor([[34958]]), 'attention_mask': tensor([[1]])}\n",
      "{'input_ids': tensor([[29631]]), 'attention_mask': tensor([[1]])}\n",
      "{'input_ids': tensor([[  89, 2286]]), 'attention_mask': tensor([[1, 1]])}\n",
      "{'input_ids': tensor([[1271]]), 'attention_mask': tensor([[1]])}\n",
      "{'input_ids': tensor([[9949]]), 'attention_mask': tensor([[1]])}\n",
      "{'input_ids': tensor([[23652,  1028]]), 'attention_mask': tensor([[1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts =  ['import', 'from', 'while', 'try', 'if', 'for', 'torch']  # feel free to add a few more that are not 100% assiciated with Python\n",
    "\n",
    "MAX_STEPS = 100\n",
    "\n",
    "for prompt in tqdm(prompts):\n",
    "    print(tokenizer(prompt, return_tensors='pt', return_token_type_ids=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00b1e103-a121-44e0-ac73-54ae58d2734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_generate(prompt, model, device, max_steps):\n",
    "    batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
    "    print(batch)\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        outputs = model(**batch)\n",
    "        #print(outputs)\n",
    "        probs = outputs.logits[0, -1].nan_to_num(nan=0.0).div(0.8).softmax(-1) #.argmax(-1).reshape(1, 1)\n",
    "        old_token = outputs.logits[0, -1].argmax(-1).reshape(1, 1)\n",
    "        #print(old_token)\n",
    "        next_token = torch.multinomial(probs, 1).reshape(1, 1)\n",
    "        #print(next_token)\n",
    "        batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
    "        batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
    "        break\n",
    "\n",
    "    return tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2b26bc3-3763-4e2e-ab99-253ab90690e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[33076]], device='cuda:0'), 'attention_mask': tensor([[1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/7 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[-0.1104, -0.3472, -0.0307,  ...,  0.0503, -0.2764,  0.0389]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<ViewBackward0>), past_key_values=((tensor([[[[ 0.5664,  0.5801, -1.3389,  ...,  0.3323, -0.7427, -0.5698]],\n",
      "\n",
      "         [[ 0.4031, -0.1638,  0.8931,  ..., -0.8618, -0.4988, -0.8623]],\n",
      "\n",
      "         [[ 1.6885, -0.5928,  0.3030,  ..., -0.1799,  0.4023, -0.7407]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2412, -2.2031, -0.1914,  ...,  0.4146, -0.1887, -1.0791]],\n",
      "\n",
      "         [[ 1.4297, -0.2235, -1.0244,  ..., -1.3994, -0.3193,  0.0953]],\n",
      "\n",
      "         [[ 2.2207, -0.0444,  1.5391,  ..., -0.1519, -0.6484, -2.9902]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.5215,  0.1376, -0.3691,  ..., -0.3887,  0.5425,  0.0561]],\n",
      "\n",
      "         [[ 0.4697,  0.1948,  0.1681,  ...,  0.1853, -0.4612, -0.4224]],\n",
      "\n",
      "         [[ 0.1459,  0.1271, -0.0180,  ...,  0.0782, -0.1848,  0.1338]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0214,  0.1268,  0.2773,  ..., -0.1138, -0.0314, -0.0565]],\n",
      "\n",
      "         [[ 0.0325,  0.4766, -0.0928,  ...,  0.1135,  0.0970,  0.0392]],\n",
      "\n",
      "         [[-0.0662, -0.2251,  0.0874,  ...,  0.0541,  0.2306,  0.1996]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.6895, -0.8716, -0.7969,  ..., -1.6846,  0.1368, -2.7383]],\n",
      "\n",
      "         [[-0.1245, -1.1768,  1.0352,  ..., -1.1221, -0.4651, -0.4927]],\n",
      "\n",
      "         [[ 2.1641, -1.0537,  0.3076,  ...,  1.4062,  1.9814,  3.2969]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6104,  0.4910, -1.2490,  ...,  1.1904, -1.3447,  1.9170]],\n",
      "\n",
      "         [[ 1.4482,  1.5332, -1.5479,  ...,  1.0381,  0.6777,  1.5488]],\n",
      "\n",
      "         [[ 2.2676, -1.9131,  0.1724,  ...,  0.2600,  2.1504,  2.2617]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 8.9264e-03,  5.1221e-01,  1.3806e-01,  ..., -5.8319e-02,\n",
      "            1.3525e-01,  2.4084e-01]],\n",
      "\n",
      "         [[ 1.7883e-01,  7.7576e-02,  1.1053e-01,  ...,  2.5757e-01,\n",
      "            1.4267e-02, -5.6592e-01]],\n",
      "\n",
      "         [[ 2.1317e-02, -6.7383e-02,  1.3599e-01,  ..., -3.5571e-01,\n",
      "           -1.7273e-01,  1.5918e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2549e-01, -5.0488e-01,  2.6025e-01,  ..., -1.7578e-02,\n",
      "           -6.6504e-01, -1.7090e-01]],\n",
      "\n",
      "         [[ 7.7759e-02,  6.1279e-01,  6.2927e-02,  ...,  1.0352e-01,\n",
      "            4.3628e-01, -1.0516e-01]],\n",
      "\n",
      "         [[ 4.0680e-02, -1.1310e-01,  1.5259e-04,  ..., -4.8065e-02,\n",
      "            1.4603e-02, -8.6731e-02]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1316, -1.2559,  1.0088,  ..., -1.4688, -0.1729, -0.1631]],\n",
      "\n",
      "         [[ 0.9888,  0.7910, -1.0645,  ...,  0.5151, -0.4412, -0.2097]],\n",
      "\n",
      "         [[ 1.5254, -0.5542,  2.0488,  ...,  0.9048,  3.9375, -1.2715]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5093, -0.3447, -0.3889,  ...,  1.4482, -5.0938, -4.6094]],\n",
      "\n",
      "         [[ 0.1666, -0.2123,  0.0745,  ..., -2.7461,  1.6055,  1.3525]],\n",
      "\n",
      "         [[ 1.9033,  2.0332,  0.8994,  ...,  1.9473,  1.3057, -0.6240]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0238, -0.3359,  0.1440,  ...,  0.2817, -0.3013, -0.5239]],\n",
      "\n",
      "         [[-0.4719,  0.1202,  0.0121,  ..., -0.3220,  0.1901, -0.0175]],\n",
      "\n",
      "         [[-0.2473,  0.1403, -0.2979,  ..., -0.0848, -0.1010,  0.2289]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2236, -0.4932,  0.1578,  ..., -0.0096,  0.0693,  0.1758]],\n",
      "\n",
      "         [[ 0.0392,  0.0332, -0.0742,  ...,  0.1709, -0.3843,  0.1008]],\n",
      "\n",
      "         [[ 0.2319,  0.1923, -0.2971,  ..., -0.0985, -0.1515,  0.1548]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0117,  0.2893, -0.1740,  ..., -0.0330,  0.3657,  1.7559]],\n",
      "\n",
      "         [[ 1.3555, -1.9512,  2.8457,  ..., -1.2549, -2.3457,  1.6289]],\n",
      "\n",
      "         [[-2.5078, -1.7725, -0.4058,  ...,  1.1348,  1.1562, -3.7031]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1328, -1.2754, -2.5820,  ..., -4.5469, -0.2659, -2.2188]],\n",
      "\n",
      "         [[-1.6045, -2.3359,  1.9971,  ..., -1.9082, -0.2686, -2.7285]],\n",
      "\n",
      "         [[ 0.1602, -1.3750,  1.1689,  ..., -0.1598, -2.0176,  1.4590]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-6.3843e-02, -5.0385e-02, -9.7229e-02,  ...,  6.9763e-02,\n",
      "           -1.4526e-01,  1.0422e-02]],\n",
      "\n",
      "         [[-4.6997e-03,  4.9744e-02,  1.7166e-02,  ...,  1.6510e-02,\n",
      "           -7.9529e-02, -1.9775e-01]],\n",
      "\n",
      "         [[-2.3596e-01, -8.5815e-02,  2.1094e-01,  ...,  3.2959e-02,\n",
      "           -1.5125e-01,  8.6670e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8501e-01,  6.8054e-02,  2.6779e-02,  ..., -1.6479e-01,\n",
      "            2.2827e-02, -5.4535e-02]],\n",
      "\n",
      "         [[ 1.8982e-02,  3.5095e-04, -4.1809e-02,  ...,  2.6123e-02,\n",
      "           -1.5068e-03, -1.8030e-01]],\n",
      "\n",
      "         [[-2.1936e-01,  1.4270e-01, -8.3496e-02,  ..., -9.7119e-01,\n",
      "           -1.2451e-01, -7.3669e-02]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.3887, -0.5073,  0.7842,  ..., -3.9297,  2.6816, -2.6152]],\n",
      "\n",
      "         [[ 4.1484, -0.8804,  3.7910,  ..., -1.4590, -1.6885, -0.5493]],\n",
      "\n",
      "         [[ 1.0449,  0.0419, -0.5835,  ...,  1.4238,  2.0156, -1.7900]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4224, -0.1272,  3.4980,  ..., -0.0834,  5.4805, -0.2490]],\n",
      "\n",
      "         [[-2.0547,  1.7266,  0.1777,  ...,  1.7754,  3.8027,  0.1211]],\n",
      "\n",
      "         [[ 6.1602,  1.5635,  0.1429,  ..., -3.0234,  0.2410,  0.1932]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.2905, -0.0467,  0.1277,  ...,  0.0173, -0.0041,  0.0843]],\n",
      "\n",
      "         [[-0.0660,  0.0203,  0.1255,  ..., -0.0318,  0.1582,  0.0717]],\n",
      "\n",
      "         [[-0.3430,  0.0273,  0.1115,  ...,  0.1927,  0.1080, -0.1777]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0931,  0.0081,  0.0050,  ..., -0.2720, -0.0164, -0.0801]],\n",
      "\n",
      "         [[-0.1442, -0.2954,  0.2015,  ..., -0.2357,  0.1637, -0.0069]],\n",
      "\n",
      "         [[ 0.0233, -0.0641, -0.0290,  ...,  0.2083, -0.1180,  0.2551]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.4944,  0.6519,  0.3054,  ...,  0.3486,  1.9004, -0.5542]],\n",
      "\n",
      "         [[ 0.4888,  0.5806,  2.2676,  ...,  1.8857,  0.8774, -1.7393]],\n",
      "\n",
      "         [[ 0.1328, -0.1616, -1.6582,  ...,  1.7627, -0.0475,  0.0391]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3057, -2.2578,  1.4434,  ..., -2.4395,  0.9292, -1.7070]],\n",
      "\n",
      "         [[-0.1401, -1.6758,  1.7451,  ...,  0.0771,  0.2083, -1.6777]],\n",
      "\n",
      "         [[ 0.4062, -1.1641, -0.2296,  ..., -0.7080,  0.2250,  0.7378]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0105, -0.0386,  0.1276,  ..., -0.0243,  0.0602,  0.1143]],\n",
      "\n",
      "         [[-0.0502, -0.1356, -0.1165,  ..., -0.0993,  0.0927,  0.0449]],\n",
      "\n",
      "         [[ 0.0065, -0.1527,  0.0677,  ..., -0.0315, -0.0283,  0.0635]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0900,  0.1755, -0.0164,  ...,  0.0044,  0.0268, -0.1311]],\n",
      "\n",
      "         [[ 0.0957, -0.0167, -0.0334,  ..., -0.0803, -0.1647, -0.0728]],\n",
      "\n",
      "         [[ 0.0624, -0.1755, -0.0246,  ...,  0.0750, -0.0286,  0.1015]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-5.2031, -4.5078, -3.8164,  ...,  4.1133, -7.0703,  0.8232]],\n",
      "\n",
      "         [[ 1.3896, -0.4592, -1.3086,  ..., -0.3293, -0.7324, -4.1406]],\n",
      "\n",
      "         [[ 4.0312, -2.7969, -1.3574,  ..., -1.7383, -4.1250,  1.1084]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4543, -2.6270, -0.0917,  ...,  2.5918, -0.1131,  1.3467]],\n",
      "\n",
      "         [[ 3.8750, -5.7031,  2.0957,  ...,  2.5059, -2.9492, -2.1973]],\n",
      "\n",
      "         [[-0.6362,  2.0918,  0.8218,  ..., -2.2285, -1.0947,  0.2474]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0440, -0.1119, -0.0187,  ..., -0.0722, -0.0144,  0.1318]],\n",
      "\n",
      "         [[-0.0076,  0.0771,  0.0057,  ...,  0.0565, -0.0068, -0.0424]],\n",
      "\n",
      "         [[-0.0665,  0.0082,  0.0004,  ...,  0.1295, -0.0096, -0.0795]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1237,  0.0006, -0.0128,  ..., -0.1323, -0.0515, -0.0450]],\n",
      "\n",
      "         [[ 0.0417, -0.2430,  0.1290,  ...,  0.0638,  0.0043, -0.0034]],\n",
      "\n",
      "         [[ 0.0447,  0.1583,  0.1735,  ...,  0.0741,  0.0298, -0.0064]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.1973, -0.5068, -0.0718,  ..., -1.8779, -1.5361,  1.0840]],\n",
      "\n",
      "         [[ 0.2542,  0.2520,  1.8154,  ..., -1.5000,  1.2207, -0.8623]],\n",
      "\n",
      "         [[-2.1973, -2.0605,  0.7607,  ...,  1.2480,  1.2070, -2.5254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7461,  1.6338, -2.3184,  ..., -0.5757, -0.8311, -2.8164]],\n",
      "\n",
      "         [[ 4.1953,  1.6250,  0.1709,  ..., -0.9160, -4.4375, -0.1238]],\n",
      "\n",
      "         [[-0.7222,  0.6802,  1.6201,  ..., -1.6211,  0.7188, -1.5430]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0296, -0.1157,  0.0405,  ..., -0.0130,  0.0390,  0.0692]],\n",
      "\n",
      "         [[-0.5874, -0.1523, -0.2101,  ...,  0.1322, -0.1309,  0.1099]],\n",
      "\n",
      "         [[-0.0033, -0.0473, -0.1364,  ..., -0.1290,  0.0090,  0.1089]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1155, -0.0082,  0.0641,  ..., -0.0269,  0.0835, -0.1315]],\n",
      "\n",
      "         [[-0.0565,  0.1075,  0.0237,  ..., -0.2742,  0.1208,  0.0306]],\n",
      "\n",
      "         [[ 0.0148, -0.0477, -0.0924,  ...,  0.0657, -0.0952, -0.0626]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.8569,  1.9385, -1.4141,  ..., -1.0273,  1.0693,  0.6519]],\n",
      "\n",
      "         [[-2.6367, -0.9712,  4.3320,  ..., -3.1582, -1.2090,  0.0352]],\n",
      "\n",
      "         [[-4.5156,  1.2520, -4.3750,  ..., -4.3477,  0.3748,  3.2695]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8281,  0.4519,  5.8516,  ...,  1.1045,  3.0000, -3.2578]],\n",
      "\n",
      "         [[ 0.8345,  2.7383, -3.7578,  ..., -3.6152, -2.1562, -6.1445]],\n",
      "\n",
      "         [[ 1.8477, -1.9209,  2.7422,  ...,  0.9478, -3.6914,  0.2522]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0532, -0.0611,  0.1037,  ..., -0.0901,  0.3064,  0.0806]],\n",
      "\n",
      "         [[-0.0304,  0.0585,  0.0443,  ..., -0.0671,  0.1709, -0.0695]],\n",
      "\n",
      "         [[ 0.0189, -0.0427, -0.0041,  ...,  0.0482, -0.0450, -0.1260]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0017,  0.0327, -0.0345,  ..., -0.1026, -0.0410, -0.0840]],\n",
      "\n",
      "         [[ 0.0367, -0.0016,  0.0393,  ..., -0.0551,  0.0519,  0.0466]],\n",
      "\n",
      "         [[ 0.1132, -0.0435, -0.0290,  ...,  0.1025, -0.0196, -0.0604]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.6694, -2.9785, -4.5781,  ..., -0.4209, -3.4746,  0.8408]],\n",
      "\n",
      "         [[-1.5713, -0.1780,  1.1748,  ...,  1.0273,  1.3564, -1.6904]],\n",
      "\n",
      "         [[ 0.7710,  0.9546,  0.1029,  ...,  0.2413, -0.7168, -0.4663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2135, -1.4961,  0.5557,  ..., -0.5732,  0.8047,  1.5713]],\n",
      "\n",
      "         [[ 1.7051,  3.2812, -0.2471,  ...,  1.3223, -0.5903,  0.7407]],\n",
      "\n",
      "         [[ 3.2695,  3.6133,  1.0146,  ..., -3.1074,  2.6797,  0.6450]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0043,  0.0490,  0.0881,  ...,  0.0678, -0.0087, -0.0114]],\n",
      "\n",
      "         [[-0.0020,  0.0159,  0.0750,  ..., -0.0415, -0.1746,  0.0575]],\n",
      "\n",
      "         [[-0.0623,  0.0099,  0.0945,  ...,  0.0977, -0.0574, -0.0845]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0826, -0.0182, -0.0585,  ...,  0.1653, -0.0461,  0.0172]],\n",
      "\n",
      "         [[-0.0168, -0.0466, -0.0317,  ...,  0.0355, -0.0314,  0.0410]],\n",
      "\n",
      "         [[ 0.0222, -0.0073,  0.0075,  ...,  0.1483, -0.0560, -0.0868]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.1501,  0.6123,  1.2871,  ..., -1.3477,  0.2314,  1.0234]],\n",
      "\n",
      "         [[-1.9277,  5.4375, -0.6094,  ...,  4.3281, -5.7188, -0.0648]],\n",
      "\n",
      "         [[ 0.1555, -1.6738,  0.1322,  ..., -3.0859,  4.6562, -5.8047]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0820,  5.1367, -4.8438,  ..., -1.8477, -3.2969,  3.1758]],\n",
      "\n",
      "         [[-5.7344, -1.4434,  2.4492,  ...,  5.8906, -1.1309, -4.1992]],\n",
      "\n",
      "         [[ 1.1279, -2.2305, -3.7383,  ..., -2.7949,  4.0781, -0.7715]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0656,  0.0567, -0.0055,  ...,  0.1003, -0.0565,  0.0787]],\n",
      "\n",
      "         [[-0.0501, -0.0267, -0.0399,  ..., -0.0489,  0.0120, -0.0493]],\n",
      "\n",
      "         [[ 0.0072, -0.1088, -0.1724,  ...,  0.0075, -0.0254,  0.0681]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0025, -0.0037, -0.0654,  ..., -0.1088, -0.1359, -0.0956]],\n",
      "\n",
      "         [[-0.0282, -0.0276,  0.0349,  ...,  0.0002,  0.0463,  0.1785]],\n",
      "\n",
      "         [[-0.0988, -0.0648, -0.0950,  ..., -0.1418, -0.0670,  0.0428]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.3528,  0.8359, -3.0371,  ..., -2.8379,  4.1875, -1.8184]],\n",
      "\n",
      "         [[ 1.1924,  0.3286, -0.9985,  ...,  1.3701,  0.4036, -0.3713]],\n",
      "\n",
      "         [[ 2.3516, -0.3970,  1.0537,  ...,  3.3867, -2.3984, -0.8301]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1689, -1.0127, -0.9438,  ...,  1.6895, -3.2949, -1.2949]],\n",
      "\n",
      "         [[ 1.9229,  1.5605, -0.0574,  ..., -0.1622,  1.1123, -0.6211]],\n",
      "\n",
      "         [[ 0.3938, -0.0726,  0.3374,  ...,  0.1919, -0.7202,  1.0020]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0033, -0.0078, -0.1324,  ...,  0.0177, -0.0308, -0.0418]],\n",
      "\n",
      "         [[-0.0321, -0.0392,  0.0933,  ..., -0.0533,  0.0898, -0.0195]],\n",
      "\n",
      "         [[-0.0130,  0.1152, -0.0375,  ...,  0.0390, -0.0203,  0.0211]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0139,  0.0450,  0.0117,  ...,  0.0971,  0.0346,  0.1091]],\n",
      "\n",
      "         [[ 0.1112, -0.0284, -0.0151,  ..., -0.0246,  0.1169, -0.1202]],\n",
      "\n",
      "         [[ 0.0426,  0.0848, -0.0238,  ...,  0.0841,  0.0432,  0.0317]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-8.2656, -6.2656, -6.1523,  ..., -0.8462, -2.4727, -7.8438]],\n",
      "\n",
      "         [[ 1.0283, -2.9980,  1.1182,  ..., -4.0898,  2.4238,  0.8745]],\n",
      "\n",
      "         [[ 2.3789,  0.4294,  1.6074,  ..., -3.6914,  1.9238, -1.4336]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.8672,  8.0859,  4.7617,  ..., -9.3984,  2.1797, -1.3594]],\n",
      "\n",
      "         [[ 2.6680, -0.1707, -2.1445,  ...,  1.5840,  2.9004, -2.8535]],\n",
      "\n",
      "         [[ 2.7012, -3.0000,  2.5332,  ..., -2.4961,  1.5459,  2.7598]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0311,  0.0336,  0.0544,  ...,  0.0734,  0.0367,  0.0154]],\n",
      "\n",
      "         [[ 0.0433, -0.0708, -0.1086,  ...,  0.0013, -0.0535,  0.0081]],\n",
      "\n",
      "         [[-0.1537, -0.0042, -0.1177,  ..., -0.0966, -0.0265,  0.0615]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1331, -0.0053, -0.0299,  ...,  0.1500, -0.0820,  0.0684]],\n",
      "\n",
      "         [[-0.0576, -0.1002,  0.0560,  ...,  0.0837, -0.0009,  0.0449]],\n",
      "\n",
      "         [[ 0.1688, -0.0726,  0.0576,  ...,  0.0226, -0.0451, -0.1553]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1525, -0.9062,  1.8125,  ...,  4.0078,  0.0746, -0.8838]],\n",
      "\n",
      "         [[ 3.7461,  1.0049,  1.0908,  ...,  0.8184, -1.6436,  0.1573]],\n",
      "\n",
      "         [[ 0.0210,  1.4404,  1.1221,  ..., -0.5967,  0.5151, -0.8262]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4414, -1.0869,  0.9082,  ...,  0.6230, -0.8896, -0.3049]],\n",
      "\n",
      "         [[-2.1484,  1.0186,  0.5166,  ...,  0.9331,  1.8262,  0.5352]],\n",
      "\n",
      "         [[ 4.0508, -0.4106, -1.4131,  ...,  0.5801, -2.5781,  0.8027]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0242, -0.0279, -0.0451,  ...,  0.0872,  0.0246, -0.0453]],\n",
      "\n",
      "         [[ 0.0388,  0.0063,  0.0331,  ...,  0.0118, -0.0082,  0.0865]],\n",
      "\n",
      "         [[-0.0494,  0.0831, -0.0336,  ..., -0.0075,  0.0363,  0.0119]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0388, -0.0036, -0.0288,  ..., -0.0271,  0.0212, -0.0435]],\n",
      "\n",
      "         [[-0.0284,  0.0287,  0.0016,  ...,  0.0533,  0.0256,  0.0448]],\n",
      "\n",
      "         [[-0.0432,  0.0800, -0.0206,  ...,  0.0634,  0.1014, -0.0224]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-6.0586,  5.1328,  0.8926,  ..., -0.1492,  1.2412,  5.2109]],\n",
      "\n",
      "         [[-1.2793,  0.9736, -3.3398,  ...,  5.0820, -1.8711,  3.9551]],\n",
      "\n",
      "         [[-1.9619, -3.3652, -4.4492,  ...,  7.0742, -5.3984, -1.3418]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2891, -3.0391, -5.6797,  ...,  9.5938, -9.3203, 10.3047]],\n",
      "\n",
      "         [[ 4.3359, -0.1164, -2.4551,  ...,  0.9990,  7.8359,  4.4766]],\n",
      "\n",
      "         [[ 3.5938, -9.0938,  7.8320,  ..., -0.7617,  2.1602,  2.3359]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0707,  0.0540,  0.0126,  ..., -0.0337, -0.0028, -0.0209]],\n",
      "\n",
      "         [[-0.0359,  0.0259,  0.1004,  ...,  0.0924,  0.0600,  0.0789]],\n",
      "\n",
      "         [[ 0.0407,  0.0103, -0.0159,  ..., -0.0269,  0.0222, -0.0115]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1288, -0.0694,  0.0090,  ...,  0.0897, -0.0205,  0.0696]],\n",
      "\n",
      "         [[-0.0337, -0.0096,  0.0901,  ...,  0.0136,  0.0556,  0.0490]],\n",
      "\n",
      "         [[-0.0256,  0.0154, -0.0612,  ...,  0.0079,  0.0275,  0.0038]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-1.1562, -1.2832,  0.0106,  ...,  0.0909,  1.3203, -1.4805]],\n",
      "\n",
      "         [[ 2.5176, -0.2377,  0.6123,  ...,  0.9443,  0.1702,  0.3962]],\n",
      "\n",
      "         [[-2.4980, -1.3975,  0.4607,  ..., -0.7075,  3.1250,  1.6211]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9653,  0.0127, -0.1515,  ..., -0.7832,  0.4021, -0.4160]],\n",
      "\n",
      "         [[-0.0746, -1.0137,  0.4463,  ..., -1.2549, -0.9580,  0.7222]],\n",
      "\n",
      "         [[-1.4346,  3.1641, -4.2305,  ...,  1.4775, -1.0146, -0.5527]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0601, -0.0428,  0.0601,  ..., -0.0787,  0.0402, -0.1196]],\n",
      "\n",
      "         [[-0.0049,  0.0344,  0.0111,  ..., -0.0789,  0.0127,  0.1202]],\n",
      "\n",
      "         [[-0.0436, -0.0835,  0.0220,  ...,  0.0082,  0.0752, -0.1159]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0349, -0.0515,  0.0092,  ..., -0.1423, -0.1006, -0.0112]],\n",
      "\n",
      "         [[-0.0138,  0.0543, -0.0685,  ..., -0.0207,  0.0449, -0.0690]],\n",
      "\n",
      "         [[-0.0120,  0.0345, -0.0525,  ...,  0.0848,  0.0386,  0.1411]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[  3.9766,  -6.9258,   8.0469,  ...,  -2.4902,   4.0430,  -2.6445]],\n",
      "\n",
      "         [[ -0.8999,   1.4766,  -0.8667,  ...,  -1.3594,   1.0928,  -0.5513]],\n",
      "\n",
      "         [[ -5.0859,  -1.5400,  -3.0703,  ...,   3.0371,   2.3594,  -5.5938]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 10.2812,   8.0078,  10.0469,  ..., -11.7578, -10.2969,  11.7422]],\n",
      "\n",
      "         [[  0.8813,   4.5508,   2.8359,  ...,   4.4609,  -2.2539,  -0.6943]],\n",
      "\n",
      "         [[  4.7930,  -3.7598,  -4.3125,  ...,  -3.2773,   5.0312,   2.5625]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0444, -0.0552,  0.0482,  ...,  0.0356,  0.0734,  0.0002]],\n",
      "\n",
      "         [[ 0.0541, -0.0509, -0.0385,  ..., -0.0473,  0.0334,  0.0168]],\n",
      "\n",
      "         [[-0.1003,  0.0220,  0.1003,  ..., -0.0909, -0.0093,  0.0424]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1109, -0.1263,  0.1501,  ..., -0.0004, -0.0566, -0.0331]],\n",
      "\n",
      "         [[-0.0243,  0.0266,  0.0225,  ..., -0.0245, -0.0474, -0.0514]],\n",
      "\n",
      "         [[-0.0549, -0.0228,  0.0547,  ...,  0.0224, -0.0615,  0.0099]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.6338, -1.5732,  0.4783,  ..., -2.3633, -1.5088,  0.7695]],\n",
      "\n",
      "         [[-0.2571, -1.2832, -0.0653,  ..., -0.0896, -0.2766, -0.9614]],\n",
      "\n",
      "         [[ 0.9375, -0.7168, -1.2988,  ..., -0.0885, -0.8589,  0.1104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7998,  0.2798,  0.8872,  ..., -2.7930,  2.9238, -0.5234]],\n",
      "\n",
      "         [[-0.7427, -1.0449, -3.8711,  ..., -3.1621,  0.6353, -0.9912]],\n",
      "\n",
      "         [[ 0.0775, -2.9160, -0.0797,  ..., -0.6919, -1.5322,  0.0640]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.1183,  0.0203, -0.0584,  ..., -0.0229, -0.0405, -0.0691]],\n",
      "\n",
      "         [[ 0.0281,  0.1053,  0.0288,  ..., -0.0684, -0.0275, -0.1096]],\n",
      "\n",
      "         [[ 0.0438, -0.0036,  0.1044,  ..., -0.0258,  0.0198,  0.0897]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0437,  0.0152, -0.0031,  ...,  0.0129, -0.0465, -0.0455]],\n",
      "\n",
      "         [[ 0.0587,  0.0009,  0.0662,  ..., -0.0130, -0.0724,  0.0754]],\n",
      "\n",
      "         [[-0.1031,  0.1047,  0.0044,  ...,  0.0047,  0.0618,  0.0302]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.0215, -3.4727, -4.4453,  ..., -4.5938, -1.5029, -6.1094]],\n",
      "\n",
      "         [[ 4.2852,  2.1250,  1.0947,  ..., -3.1270, -0.8945, -1.6094]],\n",
      "\n",
      "         [[ 0.8755,  0.7871,  3.3945,  ...,  8.9531,  2.3867,  1.5381]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4531,  3.9824, -1.0391,  ..., -0.5356, -4.0898,  0.4663]],\n",
      "\n",
      "         [[ 6.8633, -1.1094,  6.4023,  ..., -2.6875, -9.9219, -6.4102]],\n",
      "\n",
      "         [[-2.4199,  0.1289,  2.3906,  ..., -5.6875, -1.9961,  7.0469]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0182, -0.0385, -0.0245,  ...,  0.1035, -0.0958,  0.0151]],\n",
      "\n",
      "         [[ 0.0551, -0.1191, -0.0800,  ...,  0.0151, -0.0047,  0.0246]],\n",
      "\n",
      "         [[-0.0103, -0.0974,  0.0612,  ...,  0.0106, -0.0114, -0.0254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0869, -0.0591,  0.0690,  ...,  0.0450,  0.0300,  0.0175]],\n",
      "\n",
      "         [[ 0.0268, -0.0081,  0.0053,  ..., -0.1066, -0.0257,  0.0474]],\n",
      "\n",
      "         [[-0.0801,  0.0251, -0.0475,  ..., -0.0028, -0.1608, -0.0255]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 6.4893e-01,  1.1064e+00,  5.5957e-01,  ..., -7.8174e-01,\n",
      "           -1.1963e+00,  2.1387e+00]],\n",
      "\n",
      "         [[-2.3516e+00,  1.6416e+00, -7.4097e-02,  ..., -1.9199e+00,\n",
      "           -2.2559e+00, -8.6035e-01]],\n",
      "\n",
      "         [[-1.3906e+00, -6.5234e-01,  1.1074e+00,  ...,  1.7197e+00,\n",
      "            6.3232e-01,  1.0596e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1875e+00,  2.9160e+00,  8.9648e-01,  ..., -2.7930e+00,\n",
      "            2.2812e+00, -3.5371e+00]],\n",
      "\n",
      "         [[-3.5078e+00,  7.2461e-01, -1.6631e+00,  ..., -2.7637e-03,\n",
      "           -2.1465e+00, -5.7568e-01]],\n",
      "\n",
      "         [[ 9.0137e-01,  1.4873e+00, -1.5703e+00,  ..., -9.5764e-02,\n",
      "            4.0918e-01,  3.2349e-01]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0561, -0.0022,  0.0412,  ..., -0.0296, -0.0179,  0.0131]],\n",
      "\n",
      "         [[ 0.0051,  0.0564,  0.0128,  ...,  0.0264, -0.0576,  0.0096]],\n",
      "\n",
      "         [[-0.0192,  0.0912,  0.0657,  ...,  0.0035,  0.0381, -0.0660]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0146,  0.0515,  0.0006,  ...,  0.0432,  0.0555,  0.0290]],\n",
      "\n",
      "         [[ 0.0226,  0.0085,  0.0590,  ..., -0.0757,  0.0022, -0.0040]],\n",
      "\n",
      "         [[ 0.0564, -0.0914,  0.1487,  ...,  0.0897,  0.0206,  0.0889]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-6.1172,  2.9805,  8.4219,  ...,  1.7793, -6.1445,  0.3823]],\n",
      "\n",
      "         [[-2.6270, -1.3838,  3.7246,  ...,  0.7207, -0.5996,  1.5938]],\n",
      "\n",
      "         [[-2.3984,  9.3203, -6.0625,  ..., -3.7832, -0.0363,  3.4082]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.9023,  2.1797, -4.5781,  ...,  7.0938,  6.4883,  7.3359]],\n",
      "\n",
      "         [[-5.8945,  0.3369,  0.4932,  ...,  1.9395, -3.0273,  1.6992]],\n",
      "\n",
      "         [[-2.9414, -3.1934,  2.9883,  ...,  0.0627, -4.8203, -0.2949]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0515,  0.0086, -0.1029,  ...,  0.0384,  0.0138, -0.0503]],\n",
      "\n",
      "         [[ 0.0076,  0.0432,  0.1349,  ..., -0.0308, -0.0022, -0.0374]],\n",
      "\n",
      "         [[ 0.0206,  0.0335, -0.1263,  ...,  0.0626,  0.0152, -0.0193]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0873,  0.0840,  0.0062,  ..., -0.0036, -0.0675, -0.0108]],\n",
      "\n",
      "         [[ 0.1707,  0.1514, -0.0416,  ...,  0.0776,  0.0735,  0.0313]],\n",
      "\n",
      "         [[-0.1130, -0.0039, -0.0528,  ..., -0.0076, -0.0778,  0.0020]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-2.3767e-01,  3.8320e+00, -2.8945e+00,  ...,  1.2324e+00,\n",
      "           -1.6436e+00,  5.5322e-01]],\n",
      "\n",
      "         [[-2.8613e+00,  4.3242e+00, -3.2852e+00,  ...,  2.1660e+00,\n",
      "            3.4785e+00,  2.1191e+00]],\n",
      "\n",
      "         [[ 6.3525e-01,  1.5098e+00,  9.5264e-01,  ..., -2.9030e-03,\n",
      "            1.0215e+00, -4.7188e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1963e+00, -5.5312e+00,  3.7891e+00,  ..., -2.3184e+00,\n",
      "            2.4668e+00, -1.7297e-01]],\n",
      "\n",
      "         [[ 2.1875e+00,  2.3105e+00,  4.3701e-01,  ...,  9.3896e-01,\n",
      "           -8.8818e-01, -2.5449e+00]],\n",
      "\n",
      "         [[ 2.1406e+00,  4.0039e+00,  3.1982e-01,  ...,  3.2480e+00,\n",
      "           -9.3018e-01, -2.8672e+00]]]], device='cuda:1', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0145, -0.0134,  0.0311,  ..., -0.0303,  0.0155,  0.0566]],\n",
      "\n",
      "         [[-0.0125,  0.0093,  0.0618,  ...,  0.0216, -0.0379, -0.0040]],\n",
      "\n",
      "         [[ 0.0764,  0.0499, -0.0522,  ..., -0.0257,  0.0597,  0.0110]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0387,  0.0681,  0.0025,  ..., -0.0544,  0.0422, -0.0377]],\n",
      "\n",
      "         [[-0.0514, -0.0427,  0.0499,  ...,  0.0964, -0.0566, -0.0144]],\n",
      "\n",
      "         [[-0.0099, -0.0374,  0.0291,  ...,  0.0349, -0.0515,  0.0234]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.5078, -1.9453,  1.3672,  ...,  0.1650,  1.2900,  2.3027]],\n",
      "\n",
      "         [[-3.9609,  3.9707,  6.1211,  ...,  2.3906,  0.2666, -8.4453]],\n",
      "\n",
      "         [[ 4.1758, -1.7861, -5.6602,  ..., -3.0371,  3.4297, -1.0869]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8555, -1.4844,  2.4648,  ...,  6.9336,  5.6719,  2.5781]],\n",
      "\n",
      "         [[-4.9805,  0.5034,  0.7422,  ..., -1.9561,  0.8828, -1.5186]],\n",
      "\n",
      "         [[-0.9951, -4.7148,  1.2900,  ...,  2.8457, -6.4844,  1.9473]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0369, -0.0803,  0.0625,  ..., -0.0201, -0.0668, -0.0168]],\n",
      "\n",
      "         [[-0.0988,  0.0596, -0.0408,  ..., -0.0253,  0.0659, -0.0394]],\n",
      "\n",
      "         [[ 0.0346, -0.0957,  0.0327,  ..., -0.0110, -0.0674, -0.0312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3315, -0.0632, -0.0246,  ..., -0.4028, -0.2317, -0.1826]],\n",
      "\n",
      "         [[-0.0706,  0.0229, -0.0152,  ..., -0.0593, -0.0746, -0.0613]],\n",
      "\n",
      "         [[-0.0370, -0.0835,  0.0045,  ..., -0.0351, -0.0955,  0.0201]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-1.4922, -0.8789, -1.7979,  ...,  1.2441, -0.4402,  0.4609]],\n",
      "\n",
      "         [[-2.3750,  0.9668,  0.5303,  ...,  0.6602, -0.3103, -1.9160]],\n",
      "\n",
      "         [[-1.2217,  0.4700, -2.3398,  ...,  0.8994, -0.3137, -0.9858]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7251,  3.4902,  0.5439,  ...,  1.3027, -0.5615, -1.5176]],\n",
      "\n",
      "         [[-3.3457,  1.2119,  2.6055,  ...,  0.3486,  0.2842,  3.4414]],\n",
      "\n",
      "         [[-2.6602,  0.3496,  1.8994,  ..., -1.1670,  0.7461, -2.3027]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0353,  0.0697,  0.0004,  ..., -0.0028, -0.0516, -0.0957]],\n",
      "\n",
      "         [[ 0.0110, -0.0738,  0.0476,  ..., -0.0777,  0.1031,  0.0568]],\n",
      "\n",
      "         [[ 0.0688, -0.0122,  0.0469,  ..., -0.0212, -0.0729, -0.0356]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0211, -0.0837, -0.0032,  ..., -0.0296, -0.0034,  0.0232]],\n",
      "\n",
      "         [[ 0.0613,  0.0551,  0.0674,  ...,  0.0785, -0.0547,  0.0885]],\n",
      "\n",
      "         [[ 0.0506, -0.0202, -0.0068,  ..., -0.0663,  0.0119, -0.0265]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-4.4492, -3.6211, -7.8281,  ...,  2.0254,  4.4844,  2.2578]],\n",
      "\n",
      "         [[ 1.0107,  0.7505,  6.3945,  ...,  1.2227,  4.6094,  5.9883]],\n",
      "\n",
      "         [[-3.1191, -5.5078,  0.9370,  ..., -6.0586, -2.0371,  2.0273]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8516, -1.7568,  2.0762,  ...,  2.0488,  0.8701,  3.5801]],\n",
      "\n",
      "         [[-2.6699,  6.0273, -5.3203,  ...,  0.4756, -5.5742,  2.0547]],\n",
      "\n",
      "         [[-0.7803, -6.1367,  0.5703,  ...,  1.5518,  0.4250,  0.6792]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0136,  0.2131, -0.0561,  ...,  0.1511,  0.1017, -0.0382]],\n",
      "\n",
      "         [[ 0.0636, -0.0245,  0.0351,  ..., -0.0020,  0.0481, -0.0022]],\n",
      "\n",
      "         [[-0.0126, -0.0515,  0.0767,  ..., -0.0040, -0.0179,  0.0017]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0317, -0.2316,  0.1113,  ...,  0.1522, -0.0236,  0.2094]],\n",
      "\n",
      "         [[-0.0281,  0.0394, -0.0373,  ...,  0.0157, -0.0166,  0.0446]],\n",
      "\n",
      "         [[ 0.0425,  0.0406, -0.0304,  ..., -0.0098,  0.0398,  0.0610]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5874,  1.3311,  0.2267,  ...,  0.6812,  3.0059,  1.4521]],\n",
      "\n",
      "         [[ 0.9961,  1.9473, -0.2166,  ...,  1.3057,  2.7148, -0.6567]],\n",
      "\n",
      "         [[ 1.4238, -1.7070, -1.6729,  ...,  0.0543, -1.6475, -0.7046]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8169,  2.1562,  0.0914,  ..., -2.1484, -1.1475, -0.0898]],\n",
      "\n",
      "         [[-0.2529, -0.4409,  0.4434,  ..., -0.7358, -0.9561, -0.9692]],\n",
      "\n",
      "         [[ 0.7188,  0.0197, -2.3691,  ..., -0.4241,  1.3750, -0.5034]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0665,  0.0409, -0.0043,  ...,  0.0052, -0.0372,  0.0916]],\n",
      "\n",
      "         [[-0.0141,  0.0324,  0.0384,  ...,  0.0659, -0.0113,  0.0452]],\n",
      "\n",
      "         [[-0.0682,  0.0575, -0.0045,  ...,  0.0107,  0.0908, -0.0244]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0582, -0.0775, -0.0328,  ...,  0.0265, -0.1039, -0.0843]],\n",
      "\n",
      "         [[ 0.0470,  0.0635,  0.0471,  ..., -0.0157,  0.0044, -0.0089]],\n",
      "\n",
      "         [[ 0.0132,  0.0268,  0.0442,  ...,  0.0342,  0.0970, -0.3196]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-4.6367, -4.1172,  2.3438,  ..., -4.3555, -3.3125,  1.2559]],\n",
      "\n",
      "         [[-2.8594,  3.9785,  0.8066,  ...,  7.4844, -2.5977,  0.7212]],\n",
      "\n",
      "         [[-5.5078,  1.5244,  4.5938,  ...,  3.6348,  2.2090, -4.1914]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0137,  0.7949,  1.7773,  ..., -2.5996, -1.3379,  0.9912]],\n",
      "\n",
      "         [[ 1.4658,  2.3301, -1.8223,  ..., -1.1914,  7.0312,  1.3262]],\n",
      "\n",
      "         [[-9.1953, -3.6641,  3.5078,  ..., -3.0879,  2.6641, -4.0000]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0609, -0.0291,  0.0876,  ...,  0.0207,  0.0308, -0.0464]],\n",
      "\n",
      "         [[-0.0819, -0.0004, -0.0039,  ..., -0.0344, -0.0046, -0.0109]],\n",
      "\n",
      "         [[-0.0914,  0.0272, -0.0488,  ..., -0.1095, -0.0246,  0.0265]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0630,  0.0278, -0.0760,  ...,  0.0271,  0.0002,  0.0940]],\n",
      "\n",
      "         [[-0.0693,  0.0900,  0.0162,  ..., -0.0348,  0.0129,  0.0187]],\n",
      "\n",
      "         [[ 0.0148, -0.1323,  0.0435,  ..., -0.0030, -0.0527,  0.0583]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0190,  4.8125, -2.7656,  ...,  6.1289, -2.6289, -1.0713]],\n",
      "\n",
      "         [[ 3.8926, -1.1318, -2.2812,  ...,  5.4922, -1.1172,  5.7969]],\n",
      "\n",
      "         [[-2.7070,  0.2354, -1.0234,  ..., -0.2656,  0.4448,  0.7744]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0938, -1.7002,  0.6626,  ..., -2.1738,  0.3418,  0.6440]],\n",
      "\n",
      "         [[ 2.6016,  6.9766, -1.7900,  ...,  9.2500, -0.9771,  2.9727]],\n",
      "\n",
      "         [[-7.2773,  1.1064,  0.8638,  ..., -1.9365, -0.9971, -2.1016]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0262, -0.0052, -0.1057,  ..., -0.0847, -0.0244,  0.0724]],\n",
      "\n",
      "         [[-0.0489,  0.0944,  0.0484,  ...,  0.0192,  0.0634,  0.0438]],\n",
      "\n",
      "         [[-0.0628,  0.0620, -0.0266,  ..., -0.0016,  0.0406, -0.0210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0025, -0.0474, -0.0825,  ..., -0.0756, -0.0952,  0.0988]],\n",
      "\n",
      "         [[-0.0142, -0.0165,  0.0156,  ..., -0.0158,  0.0336,  0.1128]],\n",
      "\n",
      "         [[ 0.0327, -0.0201, -0.0507,  ..., -0.0639, -0.0044, -0.0229]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-7.7852,  3.9102, -1.0439,  ..., -0.6230,  1.2578, -0.6235]],\n",
      "\n",
      "         [[-5.2383,  2.2891,  1.3857,  ...,  2.7227,  2.3789,  2.1543]],\n",
      "\n",
      "         [[-1.0830,  0.2578, -3.5977,  ...,  1.1855, -2.9219, -0.6729]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7559,  8.6016,  1.2617,  ...,  1.5996, -2.1484, -2.7129]],\n",
      "\n",
      "         [[10.3438, -1.7051, -7.6484,  ...,  1.2783,  1.0498, -1.6191]],\n",
      "\n",
      "         [[-6.0156,  2.0898,  3.1230,  ...,  0.2292, -2.1484, -0.1138]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 9.8495e-03, -4.2358e-02,  7.5378e-02,  ..., -2.1744e-02,\n",
      "            1.1757e-02,  9.1248e-02]],\n",
      "\n",
      "         [[-9.7412e-02,  4.3640e-02,  3.3630e-02,  ..., -6.3660e-02,\n",
      "            2.8534e-02,  4.8645e-02]],\n",
      "\n",
      "         [[ 7.1716e-02, -1.9568e-01,  2.3328e-01,  ...,  9.2407e-02,\n",
      "           -3.2593e-02,  2.3689e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2815e-02, -5.4382e-02, -6.9519e-02,  ..., -6.5430e-02,\n",
      "            7.7534e-04, -3.8239e-02]],\n",
      "\n",
      "         [[-3.9185e-02, -8.6060e-02,  6.1035e-05,  ...,  1.5884e-02,\n",
      "           -2.7496e-02,  2.0401e-02]],\n",
      "\n",
      "         [[ 2.1851e-02, -4.3732e-02,  4.1718e-02,  ..., -1.0120e-01,\n",
      "           -9.8114e-03,  3.2593e-02]]]], device='cuda:1', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.2129e+00,  5.0049e-01, -3.7891e-01,  ...,  1.4678e+00,\n",
      "            9.1553e-01, -2.4744e-01]],\n",
      "\n",
      "         [[-1.6113e+00,  2.6445e+00,  6.8906e+00,  ...,  2.3242e+00,\n",
      "           -2.5049e-01, -3.6543e+00]],\n",
      "\n",
      "         [[-3.8438e+00,  1.6953e+00, -1.5322e+00,  ...,  1.8262e+00,\n",
      "            3.5977e+00, -1.3818e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0117e+00,  5.6836e+00, -4.3633e+00,  ..., -3.2471e-01,\n",
      "           -3.7451e-01,  2.2012e+00]],\n",
      "\n",
      "         [[ 8.2910e-01, -1.6807e+00,  9.4727e-02,  ...,  3.9209e-01,\n",
      "            3.8496e+00, -5.4321e-03]],\n",
      "\n",
      "         [[ 3.3086e+00, -1.0559e-01,  1.0205e+00,  ...,  1.9688e+00,\n",
      "           -1.7451e+00,  6.3086e+00]]]], device='cuda:1', dtype=torch.float16,\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0233, -0.0602,  0.0191,  ...,  0.0679,  0.0032, -0.0168]],\n",
      "\n",
      "         [[ 0.1081, -0.0079,  0.0460,  ...,  0.0182, -0.0032, -0.0111]],\n",
      "\n",
      "         [[ 0.0810,  0.0544, -0.0479,  ..., -0.0601,  0.1068, -0.0144]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0978, -0.0773, -0.0147,  ..., -0.0863,  0.0732, -0.0523]],\n",
      "\n",
      "         [[-0.0766, -0.0345, -0.0041,  ...,  0.0167,  0.0071, -0.0523]],\n",
      "\n",
      "         [[ 0.0617, -0.0934, -0.1809,  ..., -0.0869,  0.0257, -0.1958]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.9351, -1.1201, -4.6992,  ..., -3.4004,  2.4902, -4.0039]],\n",
      "\n",
      "         [[-1.4961, -1.4492,  6.3711,  ...,  0.5522, -4.9453,  2.0840]],\n",
      "\n",
      "         [[ 2.2910,  5.5547,  4.5430,  ..., -1.0068, -1.4502, -0.4243]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1055, -3.9727, -2.2285,  ..., -0.4297, -0.4443,  2.2930]],\n",
      "\n",
      "         [[-7.6406,  1.8389, -0.8003,  ..., -3.1289, -1.3359,  0.1089]],\n",
      "\n",
      "         [[-3.4277, -2.3203,  2.5469,  ...,  1.1299, -1.4551, -0.1156]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0351,  0.1001,  0.0106,  ...,  0.0776, -0.1847, -0.0500]],\n",
      "\n",
      "         [[ 0.0847,  0.0677, -0.0600,  ..., -0.1494, -0.0137,  0.0569]],\n",
      "\n",
      "         [[-0.0325, -0.0758,  0.1255,  ..., -0.0388,  0.0613,  0.0263]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0244,  0.0333, -0.1307,  ...,  0.0335, -0.1919, -0.0150]],\n",
      "\n",
      "         [[-0.1309,  0.1339, -0.0717,  ..., -0.0214,  0.0638, -0.0348]],\n",
      "\n",
      "         [[ 0.0098,  0.1444, -0.0131,  ..., -0.0087, -0.0458, -0.1040]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.6431,  0.4612, -0.8569,  ...,  0.3022,  0.4226, -2.8945]],\n",
      "\n",
      "         [[-1.0488, -0.4143,  0.1157,  ...,  4.3320,  1.6338, -0.3755]],\n",
      "\n",
      "         [[-0.7622,  1.2148,  0.2661,  ...,  0.8071,  0.1404, -1.7588]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4094,  3.0430,  0.4153,  ..., -0.7183,  0.9868,  2.7637]],\n",
      "\n",
      "         [[-0.5938,  2.1973,  0.6904,  ..., -0.0894, -0.9878,  1.4883]],\n",
      "\n",
      "         [[-1.5264,  2.2070,  1.6943,  ...,  0.6147,  0.0329,  0.0586]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0699,  0.0332,  0.0463,  ..., -0.0232,  0.0134, -0.0484]],\n",
      "\n",
      "         [[-0.0004,  0.0444,  0.0262,  ...,  0.0688, -0.0004, -0.0043]],\n",
      "\n",
      "         [[ 0.0498, -0.0627, -0.0645,  ...,  0.0667, -0.0876,  0.0816]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0411, -0.0236, -0.0811,  ...,  0.0569, -0.0430, -0.0069]],\n",
      "\n",
      "         [[-0.0538, -0.0388, -0.0382,  ...,  0.0431,  0.0929,  0.0159]],\n",
      "\n",
      "         [[-0.0618, -0.0542,  0.0714,  ...,  0.0017, -0.0157, -0.0030]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-4.1445,  2.3770,  4.1836,  ..., -4.7188, -2.0449, -0.1078]],\n",
      "\n",
      "         [[-2.3438, -3.1309, -2.3086,  ..., -0.0808,  1.4717, -3.2188]],\n",
      "\n",
      "         [[-4.0938, -2.9961,  4.1328,  ...,  0.3247,  2.3086, -4.7930]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2148, -0.4368, -1.3711,  ..., -0.4612,  3.2246,  1.9365]],\n",
      "\n",
      "         [[-3.6309, -4.1211,  3.6094,  ...,  2.1816, -0.7568,  8.4141]],\n",
      "\n",
      "         [[-0.2739,  1.3848, -1.1729,  ...,  5.7188,  1.3457,  0.2223]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0019,  0.1609,  0.0114,  ...,  0.0416,  0.0160,  0.0575]],\n",
      "\n",
      "         [[ 0.1030,  0.0264, -0.0320,  ...,  0.0644,  0.1041, -0.0593]],\n",
      "\n",
      "         [[-0.1039, -0.0233, -0.0659,  ...,  0.0769,  0.0316, -0.0506]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0715,  0.1257, -0.0704,  ..., -0.0418, -0.0107,  0.0621]],\n",
      "\n",
      "         [[-0.0410, -0.0042,  0.0358,  ...,  0.0278, -0.0159,  0.0148]],\n",
      "\n",
      "         [[ 0.0515, -0.0812, -0.0517,  ...,  0.0472,  0.0540, -0.0646]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0087, -0.7021,  0.2429,  ...,  0.1010, -0.1234, -0.5137]],\n",
      "\n",
      "         [[-0.8110,  3.2676, -0.2939,  ...,  1.5449, -0.1658, -1.3867]],\n",
      "\n",
      "         [[ 0.1125,  0.7261, -1.9316,  ..., -0.1133, -0.7944,  0.3806]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3125, -1.3066,  3.2539,  ..., -0.5908, -0.9932, -0.5908]],\n",
      "\n",
      "         [[ 0.0833,  2.1406, -0.2515,  ...,  0.0701,  0.5552,  2.3984]],\n",
      "\n",
      "         [[ 0.6865, -0.2507, -0.8779,  ...,  0.3989, -1.7744, -1.0166]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0515,  0.0026,  0.0536,  ..., -0.0342, -0.0057, -0.1221]],\n",
      "\n",
      "         [[ 0.0683, -0.0219,  0.0020,  ..., -0.0819,  0.0097, -0.0122]],\n",
      "\n",
      "         [[-0.0836, -0.0152,  0.1221,  ..., -0.0633, -0.0356, -0.0382]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0691, -0.0030, -0.0475,  ..., -0.0432,  0.0139, -0.0540]],\n",
      "\n",
      "         [[ 0.0699, -0.0302,  0.0604,  ...,  0.0264, -0.0417,  0.0133]],\n",
      "\n",
      "         [[ 0.0460, -0.0576, -0.0203,  ..., -0.0043,  0.0643,  0.0282]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-1.1338, -2.2695,  1.7246,  ...,  4.3281,  2.0879, -3.3438]],\n",
      "\n",
      "         [[ 0.8418,  2.7090,  0.5596,  ..., -1.1191, -0.1425, -2.9062]],\n",
      "\n",
      "         [[ 0.6611, -1.0674, -0.7764,  ...,  2.9863, -3.5098, -1.5391]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5527,  0.8237, -2.1738,  ..., -1.3232,  1.8467,  0.2307]],\n",
      "\n",
      "         [[-3.4121, -2.0020, -0.1370,  ..., -4.3086, -0.1527,  2.0781]],\n",
      "\n",
      "         [[-7.0156, -1.0977,  2.8008,  ...,  1.5488,  1.2861, -3.8613]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0839, -0.0398,  0.0708,  ...,  0.0370,  0.0356,  0.0641]],\n",
      "\n",
      "         [[ 0.0082,  0.0159, -0.1248,  ...,  0.0519, -0.0433,  0.0054]],\n",
      "\n",
      "         [[-0.0391, -0.0201,  0.0070,  ..., -0.0870,  0.1383,  0.0709]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0449,  0.0011, -0.0508,  ..., -0.0740,  0.0864,  0.0906]],\n",
      "\n",
      "         [[-0.0086,  0.0238, -0.0909,  ...,  0.0653,  0.0116, -0.0248]],\n",
      "\n",
      "         [[ 0.0564,  0.0070, -0.1431,  ..., -0.0351, -0.0994,  0.0018]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-1.8008, -0.4951,  0.3721,  ...,  0.9751, -1.4873, -1.1328]],\n",
      "\n",
      "         [[-0.0576, -1.4395, -1.0068,  ...,  0.7334, -0.0491,  0.8350]],\n",
      "\n",
      "         [[ 0.1830, -0.1160, -2.2422,  ...,  1.8809, -1.1650, -0.4282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8867,  1.2070,  0.0127,  ..., -2.3516, -0.4563, -4.1211]],\n",
      "\n",
      "         [[-1.7988,  2.2969,  2.1289,  ..., -1.3545, -0.0984, -1.4082]],\n",
      "\n",
      "         [[-1.0781, -0.0598,  1.0420,  ..., -0.4229,  0.1514, -2.4512]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[ 0.0176,  0.0569, -0.0450,  ..., -0.0324,  0.0228, -0.1121]],\n",
      "\n",
      "         [[ 0.0700, -0.0877, -0.1410,  ..., -0.0519, -0.0294,  0.1088]],\n",
      "\n",
      "         [[ 0.0578,  0.0737,  0.0801,  ..., -0.0350,  0.0686, -0.0071]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0649,  0.0421,  0.0088,  ...,  0.0973,  0.0411,  0.0768]],\n",
      "\n",
      "         [[ 0.0077, -0.0460,  0.1097,  ...,  0.0425, -0.0728, -0.0639]],\n",
      "\n",
      "         [[-0.0377, -0.0768, -0.0062,  ...,  0.0304,  0.0199, -0.0043]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.5273,  2.8262,  2.9238,  ...,  2.1113,  2.7891,  0.9194]],\n",
      "\n",
      "         [[-0.0356,  2.9961, -0.9653,  ..., -1.4707, -2.0391, -2.0000]],\n",
      "\n",
      "         [[ 0.8594,  0.2500, -1.2490,  ..., -0.3108,  0.2402, -0.8838]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7588, -2.4219, -0.4375,  ..., -0.8867,  0.4736, -5.6367]],\n",
      "\n",
      "         [[ 0.9771,  0.2935,  0.3628,  ..., -0.4319, -0.0076,  2.4004]],\n",
      "\n",
      "         [[-1.1406, -0.4534, -1.1230,  ...,  1.5537,  0.8643,  1.2021]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.0736, -0.0818, -0.0005,  ...,  0.0584,  0.0272,  0.2108]],\n",
      "\n",
      "         [[-0.0582, -0.0152, -0.1490,  ..., -0.0003, -0.0798, -0.0698]],\n",
      "\n",
      "         [[-0.1064, -0.0422, -0.0287,  ...,  0.0202,  0.0880, -0.0814]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0897, -0.0272, -0.0734,  ..., -0.0453, -0.0662,  0.0696]],\n",
      "\n",
      "         [[-0.0780,  0.0045,  0.0134,  ...,  0.0449,  0.0349,  0.1115]],\n",
      "\n",
      "         [[ 0.0670,  0.0813, -0.0038,  ...,  0.1080, -0.0149,  0.0987]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[  1.2012,   0.2018,   0.2505,  ...,  -0.5259,   0.3381,  -1.8320]],\n",
      "\n",
      "         [[ -1.6553,   0.9297,  -1.1504,  ...,  -0.4304,   0.9473,  -0.6553]],\n",
      "\n",
      "         [[ -2.5039,   0.2915,   1.3193,  ...,  -0.5762,   0.1079,  -0.9131]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  2.0234,  -2.1953,   0.3721,  ...,   1.3643,   0.9302,   0.2800]],\n",
      "\n",
      "         [[  3.6426, -14.6562,   8.3594,  ...,  -0.7505,  11.6719,   2.4043]],\n",
      "\n",
      "         [[ -2.6641,   0.3081,  -4.3711,  ...,   0.1084,   0.4749,  -1.2686]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>), tensor([[[[-0.1268, -0.0720,  0.0275,  ...,  0.0450,  0.0015,  0.0696]],\n",
      "\n",
      "         [[ 0.0263,  0.0712,  0.0807,  ..., -0.0836,  0.0966, -0.0090]],\n",
      "\n",
      "         [[-0.0872, -0.0384,  0.0961,  ...,  0.0388,  0.0461, -0.1614]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0174, -0.0849, -0.0171,  ...,  0.0054, -0.0070, -0.0469]],\n",
      "\n",
      "         [[ 0.0147,  0.1631, -0.0288,  ...,  0.0225,  0.0148,  0.1357]],\n",
      "\n",
      "         [[-0.0518, -0.0953, -0.0008,  ...,  0.0167, -0.0699, -0.1028]]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<PermuteBackward0>))), hidden_states=(tensor([[[ 0.0360, -0.0291,  0.0681,  ...,  0.0549, -0.0162, -0.0355]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.6426, -0.8428,  1.2168,  ...,  2.5098, -1.8506, -0.1992]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.2129, -0.8955,  1.0752,  ...,  3.0918, -2.5312, -1.2109]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.9473, -1.2227,  1.1709,  ...,  2.9785, -3.4902, -0.9761]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.1230, -1.2832,  0.9546,  ...,  2.6289, -4.4961, -1.2705]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.0449, -1.3877,  0.9790,  ...,  2.3574, -5.3672, -1.4883]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.0840, -1.6738,  0.9512,  ...,  2.1289, -6.2930, -1.6738]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.1406, -1.8164,  0.9370,  ...,  1.8867, -7.0977, -1.6162]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.1484, -2.1543,  0.9697,  ...,  1.7061, -7.6914, -1.7158]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.9492, -2.4961,  0.8853,  ...,  1.5459, -8.0781, -1.5527]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.0234, -2.6445,  1.0381,  ...,  1.4727, -8.3438, -1.5098]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.8984, -2.7285,  1.0781,  ...,  1.3066, -8.7109, -1.4131]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.0098, -2.9160,  0.9150,  ...,  1.1377, -9.0938, -1.5176]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.8203, -3.0039,  1.0693,  ...,  1.0361, -9.3125, -1.3857]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.9062, -3.1387,  1.0439,  ...,  0.9956, -9.6250, -1.3242]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.7871, -3.1230,  1.0234,  ...,  0.9980, -9.8906, -1.1807]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.7207,  -3.3301,   1.0928,  ...,   0.8403, -10.1094,  -1.1826]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.7363,  -3.2207,   1.1543,  ...,   0.7188, -10.1641,  -0.9878]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.6895,  -3.3203,   1.1436,  ...,   0.5908, -10.3906,  -0.9072]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.6543,  -3.3477,   1.1875,  ...,   0.4688, -10.6094,  -0.8623]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.6699,  -3.3184,   1.3271,  ...,   0.3975, -10.9219,  -0.8516]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.7383,  -3.4219,   1.2920,  ...,   0.4531, -11.0156,  -0.8550]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.9570,  -3.5977,   1.2695,  ...,   0.3794, -11.1172,  -0.7236]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -3.0039,  -3.6094,   1.2617,  ...,   0.3418, -11.0859,  -0.5596]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.9648,  -3.6133,   1.3467,  ...,   0.3350, -10.9922,  -0.5317]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.8555,  -3.6309,   1.2705,  ...,   0.3743, -10.6953,  -0.6157]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.9043,  -3.7129,   1.2725,  ...,   0.4055, -10.4922,  -0.6318]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -2.9766,  -3.7754,   1.1279,  ...,   0.5986, -10.5312,  -0.5527]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -3.1133,  -3.8828,   1.0684,  ...,   0.6421, -10.6094,  -0.4248]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -3.0918,  -3.8848,   0.8047,  ...,   0.6763, -10.4062,  -0.1747]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[ -3.0566,  -3.9414,   0.6611,  ...,   0.8716, -10.3203,   0.1055]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.0684, -3.9297,  0.3916,  ...,  1.1709, -9.8359,  0.1101]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.2129, -4.1250,  0.1538,  ...,  1.4160, -9.5547,  0.3667]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.2441, -4.1055, -0.1092,  ...,  1.6064, -9.2188,  0.4983]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.1426, -4.0625, -0.2969,  ...,  1.7617, -8.7266,  0.5391]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-3.0195, -4.0000, -0.3733,  ...,  1.6670, -7.9727,  0.5693]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.5996, -4.0000, -0.4731,  ...,  1.4736, -7.2500,  0.7354]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-2.1914, -3.9492, -0.4612,  ...,  1.3506, -6.2734,  0.3960]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[-0.1104, -0.3472, -0.0307,  ...,  0.0503, -0.2764,  0.0389]]],\n",
      "       device='cuda:1', dtype=torch.float16, grad_fn=<ViewBackward0>)), attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "update_memory() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m after_finetuning_samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(prompts):\n\u001b[0;32m----> 3\u001b[0m     after_finetuning_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcustom_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_STEPS\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m after_finetuning_samples\n",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m, in \u001b[0;36mcustom_generate\u001b[0;34m(prompt, model, device, max_steps)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     probs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnan_to_num(nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m0.8\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#.argmax(-1).reshape(1, 1)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rugpt_dev/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 85\u001b[0m, in \u001b[0;36mLTM_GPT.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     82\u001b[0m memory \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_ltm_blocks:\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m block(hidden_states)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: update_memory() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "after_finetuning_samples = []\n",
    "for prompt in tqdm(prompts):\n",
    "    after_finetuning_samples.append(custom_generate(prompt, model, device, MAX_STEPS))\n",
    "after_finetuning_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2cb81d-971c-4240-8aa6-1ce689915863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427b55b-1040-4532-b0b3-8e12810c21a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be29ade-27b2-485a-9b05-60f4c4c5b4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330d6bb-50f3-4a8f-85ff-d141c88ba309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5bf2d-e0b7-461e-9773-624b5f343856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e97d3f-f8eb-4eb4-8346-1ebf58555c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0f4b6-f149-4ff0-90d1-d40e514278af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03486b6-ae21-4696-9656-019798ab9c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ec581-c299-4f51-8468-f84c377e1a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f7938-6460-4055-820f-80905cc302f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebee22e-8aaf-48c9-b8b2-34dda72ffa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec01194-2d55-41e2-97f4-1a7730ffb255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12289ae8-1011-4422-b1e6-d5c69eef5642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95210ae0-4f18-4e33-abe5-23016e7c0be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046e5a0-4dba-450d-adc8-b7158d297805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa818dbd-d310-4aca-b57b-c1c4e265b911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b669a-7646-4d8a-8fa8-c0b6d429ef56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bdad0-d8c3-47c9-8665-5a1a83a02783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036148b-45f2-49fc-9df4-81059f54f54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136f161-f03d-43c4-8227-0ae0a64ea049",
   "metadata": {},
   "outputs": [],
   "source": [
    "[-3 + i for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c220098-1b3c-4ca7-93a5-c5e650817e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import (\n",
    "    ModelOutput,\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutputWithPast,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "from typing import Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31024f97-4192-4b1b-958b-111b6112b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT2_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\n",
    "            `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\n",
    "            `past_key_values[0][0].shape[-2]` (`sequence_length` of input past key value states). Indices of input\n",
    "            sequence tokens in the vocabulary.\n",
    "\n",
    "            If `past_key_values` is used, only `input_ids` that do not have their past calculated should be passed as\n",
    "            `input_ids`.\n",
    "\n",
    "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        past_key_values (`Tuple[Tuple[torch.Tensor]]` of length `config.n_layers`):\n",
    "            Contains precomputed hidden-states (key and values in the attention blocks) as computed by the model (see\n",
    "            `past_key_values` output below). Can be used to speed up sequential decoding. The `input_ids` which have\n",
    "            their past given to this model should not be passed as `input_ids` as they have already been computed.\n",
    "        attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            If `past_key_values` is used, `attention_mask` needs to contain the masking strategy that was used for\n",
    "            `past_key_values`. In other words, the `attention_mask` always has to have the length:\n",
    "            `len(past_key_values) + len(input_ids)`\n",
    "\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        token_type_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,\n",
    "            1]`:\n",
    "\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "\n",
    "            If `past_key_values` is used, optionally only the last `inputs_embeds` have to be input (see\n",
    "            `past_key_values`).\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\"\n",
    "_CHECKPOINT_FOR_DOC = \"openai-community/gpt2\"\n",
    "_CONFIG_FOR_DOC = \"GPT2Config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a277c-903a-49f7-b774-5ead54886815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTM_GPT2Model(GPT2Model):\n",
    "    \"\"\" Custom LTM GPT2 layer with memory \"\"\"\n",
    "    def __init__(self, model: GPT2Model, cnt_blocks_with_memory=2):\n",
    "        super().__init__(model.config)\n",
    "        self.base_model = model\n",
    "        \n",
    "        self.embed_dim = self.base_model.embed_dim\n",
    "\n",
    "        self.wte = self.base_model.wte\n",
    "        self.wpe = self.base_model.wpe\n",
    "\n",
    "        self.drop = self.base_model.drop\n",
    "        self.h = self.base_model.h[:-cnt_blocks_with_memory]\n",
    "        self.transformer_ltm_blocks_h = nn.ModuleList([\n",
    "            LTMGPT2Block(self.base_model.h[-cnt_blocks_with_memory+i]) for i in range(cnt_blocks_with_memory)\n",
    "        ])\n",
    "        self.ln_f = self.base_model.ln_f\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = self.base_model.model_parallel\n",
    "        self.device_map = self.base_model.device_map\n",
    "        self.gradient_checkpointing = self.base_model.gradient_checkpointing\n",
    "        \n",
    "        # Initialize weights and apply final processing\n",
    "        # self.post_init()\n",
    "        \n",
    "    \n",
    "    \n",
    "    @add_start_docstrings_to_model_forward(GPT2_INPUTS_DOCSTRING)\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=BaseModelOutputWithPastAndCrossAttentions,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.base_model.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.base_model.config.output_hidden_states\n",
    "        )\n",
    "        use_cache = use_cache if use_cache is not None else self.base_model.config.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.base_model.config.use_return_dict\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            self.base_model.warn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n",
    "            input_shape = input_ids.size()\n",
    "            input_ids = input_ids.view(-1, input_shape[-1])\n",
    "            batch_size = input_ids.shape[0]\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "            batch_size = inputs_embeds.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.view(-1, input_shape[-1])\n",
    "\n",
    "        if past_key_values is None:\n",
    "            past_length = 0\n",
    "            past_key_values = tuple([None] * len(self.h))\n",
    "        else:\n",
    "            past_length = past_key_values[0][0].size(-2)\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(past_length, input_shape[-1] + past_length, dtype=torch.long, device=device)\n",
    "            position_ids = position_ids.unsqueeze(0)\n",
    "\n",
    "        # GPT2Attention mask.\n",
    "        if attention_mask is not None:\n",
    "            if batch_size <= 0:\n",
    "                raise ValueError(\"batch_size has to be defined and > 0\")\n",
    "            attention_mask = attention_mask.view(batch_size, -1)\n",
    "            # We create a 3D attention mask from a 2D tensor mask.\n",
    "            # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "            # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
    "            # this attention mask is more simple than the triangular masking of causal attention\n",
    "            # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "            attention_mask = attention_mask[:, None, None, :]\n",
    "\n",
    "            # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "            # masked positions, this operation will create a tensor which is 0.0 for\n",
    "            # positions we want to attend and the dtype's smallest value for masked positions.\n",
    "            # Since we are adding it to the raw scores before the softmax, this is\n",
    "            # effectively the same as removing these entirely.\n",
    "            attention_mask = attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
    "            attention_mask = (1.0 - attention_mask) * torch.finfo(self.dtype).min\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.base_model.config.add_cross_attention and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_attention_mask = self.invert_attention_mask(encoder_attention_mask) # self.base_model.\n",
    "        else:\n",
    "            encoder_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # head_mask has shape n_layer x batch x n_heads x N x N\n",
    "        head_mask = self.get_head_mask(head_mask, self.base_model.config.n_layer) # self.base_model.\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.wte(input_ids)\n",
    "        position_embeds = self.wpe(position_ids)\n",
    "        hidden_states = inputs_embeds + position_embeds\n",
    "\n",
    "        if token_type_ids is not None:\n",
    "            token_type_embeds = self.wte(token_type_ids)\n",
    "            hidden_states = hidden_states + token_type_embeds\n",
    "\n",
    "        hidden_states = self.drop(hidden_states)\n",
    "\n",
    "        output_shape = (-1,) + input_shape[1:] + (hidden_states.size(-1),)\n",
    "\n",
    "        if self.gradient_checkpointing and self.training:\n",
    "            if use_cache:\n",
    "                logger.warning_once(\n",
    "                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                )\n",
    "                use_cache = False\n",
    "\n",
    "        presents = () if use_cache else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        for i, (block, layer_past) in enumerate(zip(self.h, past_key_values)):\n",
    "            # Model parallel\n",
    "            if self.model_parallel:\n",
    "                torch.cuda.set_device(hidden_states.device)\n",
    "                # Ensure layer_past is on same device as hidden_states (might not be correct)\n",
    "                if layer_past is not None:\n",
    "                    layer_past = tuple(past_state.to(hidden_states.device) for past_state in layer_past)\n",
    "                # Ensure that attention_mask is always on the same device as hidden_states\n",
    "                if attention_mask is not None:\n",
    "                    attention_mask = attention_mask.to(hidden_states.device)\n",
    "                if isinstance(head_mask, torch.Tensor):\n",
    "                    head_mask = head_mask.to(hidden_states.device)\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                outputs = self._gradient_checkpointing_func(\n",
    "                    block.__call__,\n",
    "                    hidden_states,\n",
    "                    None,\n",
    "                    attention_mask,\n",
    "                    head_mask[i],\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                    use_cache,\n",
    "                    output_attentions,\n",
    "                )\n",
    "            else:\n",
    "                outputs = block(\n",
    "                    hidden_states,\n",
    "                    layer_past=layer_past,\n",
    "                    attention_mask=attention_mask,\n",
    "                    head_mask=head_mask[i],\n",
    "                    encoder_hidden_states=encoder_hidden_states,\n",
    "                    encoder_attention_mask=encoder_attention_mask,\n",
    "                    use_cache=use_cache,\n",
    "                    output_attentions=output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = outputs[0]\n",
    "            if use_cache is True:\n",
    "                presents = presents + (outputs[1],)\n",
    "\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (outputs[2 if use_cache else 1],)\n",
    "                if self.config.add_cross_attention:\n",
    "                    all_cross_attentions = all_cross_attentions + (outputs[3 if use_cache else 2],)\n",
    "\n",
    "            # Model Parallel: If it's the last layer for that device, put things on the next device\n",
    "            if self.model_parallel:\n",
    "                for k, v in self.device_map.items():\n",
    "                    if i == v[-1] and \"cuda:\" + str(k) != self.last_device:\n",
    "                        hidden_states = hidden_states.to(\"cuda:\" + str(k + 1))\n",
    "\n",
    "        memory = hidden_states\n",
    "        \n",
    "        for i, block in enumerate(self.transformer_ltm_blocks_h): # TODO add flags like in `for` up\n",
    "            block.update_memory(memory)\n",
    "            hidden_states = block(hidden_states)\n",
    "        \n",
    "        hidden_states = self.ln_f(hidden_states)\n",
    "\n",
    "        hidden_states = hidden_states.view(output_shape)\n",
    "        # Add last hidden state\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [hidden_states, presents, all_hidden_states, all_self_attentions, all_cross_attentions]\n",
    "                if v is not None\n",
    "            )\n",
    "\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=presents,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=all_cross_attentions,\n",
    "        )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6006f-8f15-4db8-9535-770fc5ffb77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a8463-606e-4b0f-92a6-7eabc7dc7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90621710-05dc-4db5-a997-1420dba1458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80545898-0e60-4209-baaf-068d18c49fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer = LTM_GPT2Model(model.transformer)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7138929-7180-443f-be23-6654e3b64e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTM_GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71001b-980f-4904-b678-7db46a08d2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a986e4-cd69-4c60-a977-52d06702271a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb6ea9-3b6e-44a5-987c-3e6fd97dc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LTM_GPT(GPT2LMHeadModel):\n",
    "#     \"\"\" Custom LTM GPT2 layer with memory \"\"\"\n",
    "#     def __init__(self, model: GPT2LMHeadModel, cnt_blocks_with_memory=2):\n",
    "#         super().__init__()\n",
    "#         self.base_model = model\n",
    "#         self.transformer = self.base_model.tranformer GPT2Model(config)\n",
    "#         self.transformer.h = self.base_model.transformer.h[:-cnt_blocks_with_memory]\n",
    "        \n",
    "#         self.transformer_ltm_blocks = nn.ModuleList([\n",
    "#             LTMGPT2Block(self.base_model.transformer.h[-cnt_blocks_with_memory+i]) for i in range(cnt_blocks_with_memory)\n",
    "#         ])\n",
    "        \n",
    "#         self.lm_head = self.base_model.lm_head\n",
    "\n",
    "#         # Model parallel\n",
    "#         # self.model_parallel = False\n",
    "#         # self.device_map = None\n",
    "\n",
    "#         # Initialize weights and apply final processing\n",
    "#         # self.post_init()\n",
    "    \n",
    "#     @add_start_docstrings_to_model_forward(GPT2_INPUTS_DOCSTRING)\n",
    "#     @add_code_sample_docstrings(\n",
    "#         checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "#         output_type=CausalLMOutputWithCrossAttentions,\n",
    "#         config_class=_CONFIG_FOR_DOC,\n",
    "#     )\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         input_ids: Optional[torch.LongTensor] = None,\n",
    "#         past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "#         attention_mask: Optional[torch.FloatTensor] = None,\n",
    "#         token_type_ids: Optional[torch.LongTensor] = None,\n",
    "#         position_ids: Optional[torch.LongTensor] = None,\n",
    "#         head_mask: Optional[torch.FloatTensor] = None,\n",
    "#         inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "#         encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "#         encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "#         labels: Optional[torch.LongTensor] = None,\n",
    "#         use_cache: Optional[bool] = None,\n",
    "#         output_attentions: Optional[bool] = None,\n",
    "#         output_hidden_states: Optional[bool] = None,\n",
    "#         return_dict: Optional[bool] = None,\n",
    "#     ) -> Union[Tuple, CausalLMOutputWithCrossAttentions]:\n",
    "#         r\"\"\"\n",
    "#         labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "#             Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\n",
    "#             `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\n",
    "#             are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\n",
    "#         \"\"\"\n",
    "#         return_dict = return_dict if return_dict is not None else self.base_model.config.use_return_dict\n",
    "\n",
    "#         transformer_outputs = self.transformer(\n",
    "#             input_ids,\n",
    "#             past_key_values=past_key_values,\n",
    "#             attention_mask=attention_mask,\n",
    "#             token_type_ids=token_type_ids,\n",
    "#             position_ids=position_ids,\n",
    "#             head_mask=head_mask,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "#             encoder_hidden_states=encoder_hidden_states,\n",
    "#             encoder_attention_mask=encoder_attention_mask,\n",
    "#             use_cache=use_cache,\n",
    "#             output_attentions=output_attentions,\n",
    "#             output_hidden_states=output_hidden_states,\n",
    "#             return_dict=return_dict,\n",
    "#         )\n",
    "#         hidden_states = transformer_outputs[0]\n",
    "        \n",
    "#         # Init memory as hidden_states from 37 layers\n",
    "#         hidden_states\n",
    "\n",
    "#         # Set device for model parallelism\n",
    "#         if self.base_model.model_parallel:\n",
    "#             torch.cuda.set_device(self.transformer.first_device)\n",
    "#             hidden_states = hidden_states.to(self.lm_head.weight.device)\n",
    "\n",
    "#         lm_logits = self.lm_head(hidden_states)\n",
    "\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             # move labels to correct device to enable model parallelism\n",
    "#             labels = labels.to(lm_logits.device)\n",
    "#             # Shift so that tokens < n predict n\n",
    "#             shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "#             shift_labels = labels[..., 1:].contiguous()\n",
    "#             # Flatten the tokens\n",
    "#             loss_fct = CrossEntropyLoss()\n",
    "#             loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "#         if not return_dict:\n",
    "#             output = (lm_logits,) + transformer_outputs[1:]\n",
    "#             return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "#         return CausalLMOutputWithCrossAttentions(\n",
    "#             loss=loss,\n",
    "#             logits=lm_logits,\n",
    "#             past_key_values=transformer_outputs.past_key_values,\n",
    "#             hidden_states=transformer_outputs.hidden_states,\n",
    "#             attentions=transformer_outputs.attentions,\n",
    "#             cross_attentions=transformer_outputs.cross_attentions,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd2fe9-b01b-49af-a2d6-acce67398121",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf155a6-1d6d-46df-b0bc-a64c1ff86c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c68a8-bb75-4577-8d61-d943fbe0add9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b2c48f-01d5-426b-a83a-e79cdf01da58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1ec17-979f-4e4a-859f-634d75091640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db387cf-ae03-4055-973b-751968f92ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) / sum(p.numel() for p in model.parameters())\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa29fd1-b5bd-43bd-b6c1-5cb7aff8b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db82518-86b2-4da2-9897-b76d4af6d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "for param in model.transformer.transformer_ltm_blocks_h.parameters():\n",
    "    param.requires_grad=True\n",
    "    # param.data = param.data.to(torch.float32)\n",
    "\n",
    "for param in model.transformer.ln_f.parameters():\n",
    "    param.requires_grad=True\n",
    "    # param.data = param.data.to(torch.float32)\n",
    "\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad=True\n",
    "    # param.data = param.data.to(torch.float32)\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36544930-9703-4a1f-b37b-42eba15bb42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e8325-59cf-45be-8297-39a7a54c2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Init LTM gpt blocks\n",
    "# model.transformer.h[-2] = LTMGPT2Block(model.transformer.h[-2])\n",
    "# model.transformer.h[-1] = LTMGPT2Block(model.transformer.h[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e0b57-0a02-4955-98fa-9c559e8f231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upcast\n",
    "# for param in model.transformer.h[-2:].parameters():\n",
    "#     param.data = param.data.to(torch.float32)\n",
    "    \n",
    "# for param in model.transformer.ln_f.parameters():\n",
    "#     param.requires_grad=True\n",
    "#     param.data = param.data.to(torch.float32)\n",
    "\n",
    "# for param in model.lm_head.parameters():\n",
    "#     param.requires_grad=True\n",
    "#     param.data = param.data.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04654acc-abe2-477a-8099-247e407cc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899717fa-1a07-4645-9c4d-999324b7aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035fc13-efc0-40bc-97f7-8f49e62dd9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruGPT-3.5-13B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8bf5a-7023-42cb-acca-e7d7b56ee9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dataset = load_dataset(\"codeparrot/codeparrot-clean-valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90424abe-c84e-4a32-8abb-5db5bf77f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts =  ['import', 'from', 'while', 'try', 'if', 'for', 'torch']  # feel free to add a few more that are not 100% assiciated with Python\n",
    "\n",
    "MAX_STEPS = 100\n",
    "\n",
    "for prompt in tqdm(prompts):\n",
    "    print(tokenizer(prompt, return_tensors='pt', return_token_type_ids=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5e785-26b8-4768-8d51-ed33d6d37695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_generate(prompt, model, device, max_steps):\n",
    "    batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
    "    print(batch)\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        outputs = model(**batch)\n",
    "        #print(outputs)\n",
    "        probs = outputs.logits[0, -1].nan_to_num(nan=0.0).div(0.8).softmax(-1) #.argmax(-1).reshape(1, 1)\n",
    "        old_token = outputs.logits[0, -1].argmax(-1).reshape(1, 1)\n",
    "        #print(old_token)\n",
    "        next_token = torch.multinomial(probs, 1).reshape(1, 1)\n",
    "        #print(next_token)\n",
    "        batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
    "        batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
    "        break\n",
    "\n",
    "    return tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4848d2b-b134-41e2-836b-82dc45b76d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673a7a7-0663-4b02-bd4f-2fad774fbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_finetuning_samples = []\n",
    "for prompt in tqdm(prompts):\n",
    "    after_finetuning_samples.append(custom_generate(prompt, model, device, MAX_STEPS))\n",
    "after_finetuning_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb45790-6e71-48cc-b76d-96b36c677ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f652b89-ed17-476c-8f7a-93215b404cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a67d7-031c-42f8-8a1d-9629e22e3bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70567fcc-d2ae-4649-a437-2d0c40bc9e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f06b5-ffb9-4f6a-89ec-5318b2a25f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1baba-f148-4eee-9b6f-50240aebba3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202d09e-9dce-4f13-b04e-2cb98cda387c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210ece3-cf88-4137-979f-620aee4db2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac355dc-9fa5-41a2-8a4f-b79a65feec35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ce52c-3899-4372-be2b-0503ab5a20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
